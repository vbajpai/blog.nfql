<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>NFQL</title>
 <link href="http://vbajpai.github.com/blog.nfql/atom.xml" rel="self"/>
 <link href="http://vbajpai.github.com/blog.nfql"/>
 <updated>2012-09-23T20:34:15+02:00</updated>
 <id>http://vbajpai.github.com/blog.nfql</id>
 <author>
   <name>Vaibhav Bajpai</name>
   <email>contact@vaibhavbajpai.com</email>
 </author>

 
 <entry>
   <title>Better Execution Engine Usage on Run</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/05/31/better-execution-engine-usage-on-run"/>
   <updated>2012-05-31T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/05/31/better-execution-engine-usage-on-run</id>
   <content type="html">&lt;p&gt;Better Usage:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bin/engine
usage: bin/engine [OPTIONS] queryfile tracefile        query the specified trace
   or: bin/engine [OPTIONS] queryfile -                read the trace from stdin

OPTIONS:
-d, --debug              enable debugging mode
-v, --verbose            increase the verbosity level
-h, --help               display this help and exit
-V, --version            output version information and exit&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>v2.4: it's portable</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/05/19/v24-its-portable"/>
   <updated>2012-05-19T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/05/19/v24-its-portable</id>
   <content type="html">&lt;p&gt;Summary: (since after &lt;code&gt;v0.3&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; git show v0.4

tag v0.4
Tagger: Vaibhav Bajpai &amp;lt;contact@vaibhavbajpai.com&amp;gt;
Date:   Fri May 18 15:07:42 2012 +0200
Commit 00c17385e37dd944c9139205a5eb3660c707858a	

*  _GNU_SOURCE feature test MACRO and -std=c99
*  (__FreeBSD, __APPLE__) and __linux MACROS around qsort_r(…)
*  reverted to a flat source structure for the CMake build process.
*  CMake command to call a script to create auto-generated sources and headers.
*  CMake command to call a scripts in queries/ to put JSON queries in examples/
*  Makefile to automate invocation of CMake commands.
*  installation instruction for Ubuntu.
*  installation instruction for Mac OS X.&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Execution Engine on Mac OS X</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/05/18/execution-engine-on-mac-os-x"/>
   <updated>2012-05-18T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/05/18/execution-engine-on-mac-os-x</id>
   <content type="html">&lt;p&gt;Tried on Mac OS X 10.7.&lt;/p&gt;

&lt;p&gt;Install &lt;a href='http://mxcl.github.com/homebrew/'&gt;Homebrew &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Install CMake&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; brew install cmake&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Flow-Tools from source&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; wget http://dl.dropbox.com/u/500389/flow-tools-0.68.4.tar.bz2
&amp;gt;&amp;gt; tar -xvf flow-tools-0.68.4.tar.bz2

[flow-tools-0.68.4] &amp;gt;&amp;gt; ./configure
[flow-tools-0.68.4] &amp;gt;&amp;gt; make 
[flow-tools-0.68.4] &amp;gt;&amp;gt; make install	&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install JSON Manipulation Library Package&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; brew install json-c&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Build Engine&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; make CMAKE_PREFIX_PATH=/usr/local/flow-tools/&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run Engine&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; bin/engine examples/query-http-tcp-session.json examples/trace.ft&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Doxygen (optional)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; brew install doxygen&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install GraphVIZ (optional)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; brew install graphviz&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generate Documentation (optional)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; make doc	&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cleanup&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; make clean&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Execution Engine on Ubuntu</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/05/17/execution-engine-on-ubuntu"/>
   <updated>2012-05-17T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/05/17/execution-engine-on-ubuntu</id>
   <content type="html">&lt;p&gt;Tried on Ubuntu 10.04 (LTS) x86_64 and 12.04 (LTS) x86_64&lt;/p&gt;

&lt;p&gt;Install CMake&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; sudo apt-get install cmake&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Flow-tool Development Package&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; sudo apt-get install flow-tools-dev	&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Compression Library Development Package&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; sudo apt-get install zlib1g-dev&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install JSON Manipulation Library Development Package&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; sudo apt-get install libjson0-dev&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Build Engine&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; make&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run Engine&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; bin/engine examples/query-http-tcp-session.json examples/trace.ft&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Doxygen (optional)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; sudo apt-get install doxygen&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install GraphVIZ (optional)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; sudo apt-get install graphviz&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generate Documentation (optional)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; make doc&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cleanup&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; make clean&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>CMake Build Process</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/05/14/cmake-build-process"/>
   <updated>2012-05-14T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/05/14/cmake-build-process</id>
   <content type="html">&lt;p&gt;Reverting to a flat source structure.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import this
The Zen of Python, by Tim Peters
...
Flat is better than nested.
...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The previous source structure was unnecesarily nested for the simple number of source files that we have. Switching to a flat source structure reduced the CMake compilation complexity alot. This is how it looks like now:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; tree
.
|-- examples/
|   `-- trace.ft
|-- include/
|   |-- base.h
|   |-- branch.h
|   |-- echo.h
|   |-- errorhandlers.h
|   |-- filter.h
|   |-- flowy.h
|   |-- ftreader.h
|   |-- grouper.h
|   |-- groupfilter.h
|   |-- merger.h
|   |-- pipeline.h
|   |-- ungrouper.h
|   `-- utils.h
|-- scripts/
|   |-- queries/
|   |   |-- build-ftp-tcp-session.py*
|   |   |-- build-http-octets.py*
|   |   |-- build-http-tcp-session.py*
|   |   `-- build-https-tcp-session.py*
|   `-- generate-functions.py*
|-- src/
|   |-- base.c
|   |-- branch.c
|   |-- echo.c
|   |-- errorhandlers.c
|   |-- filter.c
|   |-- flowy.c
|   |-- ftreader.c
|   |-- grouper.c
|   |-- groupfilter.c
|   |-- merger.c
|   |-- ungrouper.c
|   `-- utils.c
|-- CMakeLists.txt
|-- Doxyfile
|-- Makefile
`-- README.md&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CMake compilation creates a &lt;code&gt;.build/&lt;/code&gt; and puts the executable binary in &lt;code&gt;bin/&lt;/code&gt;. The auto generated C sources and headers goto &lt;code&gt;.build/&lt;/code&gt; as well and are automatically included and linked in the final binary.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# custom command to prepare auto-generated sources
add_custom_command (
  OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/auto-assign.h
         ${CMAKE_CURRENT_BINARY_DIR}/auto-assign.c
         ${CMAKE_CURRENT_BINARY_DIR}/auto-comps.h
         ${CMAKE_CURRENT_BINARY_DIR}/auto-comps.c
  COMMAND python ${CMAKE_SOURCE_DIR}/scripts/generate-functions.py
  COMMENT &amp;quot;Generating: auto-comps{h,c} and auto-assign.{h,c}&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CMake compilation also runs the build query scripts defined in &lt;code&gt;scripts/queries/&lt;/code&gt; to generate some examples &lt;code&gt;JSON&lt;/code&gt; queries and moves them to the &lt;code&gt;examples/&lt;/code&gt; folder ready to be used by the &lt;code&gt;bin/engine&lt;/code&gt; binary.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# custom command to generate examples
file(GLOB pyFILES ${CMAKE_SOURCE_DIR}/scripts/queries/*.py)
foreach(pyFILE ${pyFILES})
  set(query &amp;quot;${pyFILE}_query&amp;quot;)
  add_custom_command (
    OUTPUT ${query}
    WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}/examples/
    COMMAND python ${pyFILE}
    COMMENT &amp;quot;Generating: JSON example query using ${pyFILE}&amp;quot;
  )
  list(APPEND queryFILES ${query})
endforeach(pyFILE)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to avoid doing -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] &amp;gt;&amp;gt; mkdir .build
[engine] &amp;gt;&amp;gt; cd .build
[.build] &amp;gt;&amp;gt; cmake ..
[.build] &amp;gt;&amp;gt; make
[.build] &amp;gt;&amp;gt; cd ..
[engine] &amp;gt;&amp;gt; rm -r .build&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;taking inspiration from Dirk Joel-Luchini Colbry (1), I am using a Makefile that calls CMake to automate this operation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;make: build/Makefile
  (cd .build; make)

build/Makefile: build
  (cd .build; cmake -D CMAKE_PREFIX_PATH=$(CMAKE_PREFIX_PATH) ..)

build:
  mkdir -p .build&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Additional targets to &lt;code&gt;clean&lt;/code&gt; and generate Doxygen documentation &lt;code&gt;doc&lt;/code&gt; also exist. The generated documentation goes in &lt;code&gt;doc/&lt;/code&gt; and is subsequently deleted by &lt;code&gt;make clean&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;doc: Doxyfile
  (mkdir -p doc; doxygen Doxyfile)

clean:
  rm -f -r .build
  rm -f -r bin
  rm -f -r doc
  rm -f -r examples/*.json&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Makefile can also take &lt;code&gt;CMAKE_PREFIX_PATH&lt;/code&gt; as an argument and pass it on to CMake. &lt;code&gt;CMAKE_PREFIX_PATH&lt;/code&gt; is used to supply arbitrary location of external libraries and include PATHS.&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='https://wiki.hpcc.msu.edu/display/~colbrydi@msu.edu/2010/08/19/Cmake+Makefile'&gt;CMake Makefile &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Porting the Execution Engine to GNU/Linux</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/05/11/porting-the-execution-engine-to-gnulinux"/>
   <updated>2012-05-11T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/05/11/porting-the-execution-engine-to-gnulinux</id>
   <content type="html">&lt;p&gt;&lt;code&gt;glibc&lt;/code&gt; manual (1) defines &lt;code&gt;_GNU_SOURCE&lt;/code&gt; as -&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you define this macro, everything is included: &lt;br /&gt;ISO C89, ISO C99, POSIX.1, POSIX.2, BSD, SVID, X/Open, LFS, and GNU extensions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since the &lt;code&gt;flow-tools&lt;/code&gt; library is based on BSD specific headers. Adding &lt;code&gt;_GNU_SOURCE&lt;/code&gt; brought the features from both world when trying to compile on GNU/Linux.&lt;/p&gt;

&lt;p&gt;The order of arguments of &lt;code&gt;qsort_r(...)&lt;/code&gt; apparantely are different on &lt;code&gt;glibc&lt;/code&gt; and &lt;code&gt;BSD&lt;/code&gt; (2)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;glibc:&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;extern void qsort_r (
                      void *__base, 
                      size_t __nmemb, 
                      size_t __size,
                      __compar_d_fn_t __compar, 
                      void *__arg) __nonnull ((1, 4)
                    );&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;BSD:&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void qsort_r (
               void *base, 
               size_t nel, 
               size_t width, 
               void *thunk,
               int (*compar)(void *, const void *, const void *)
             );&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The invocation of &lt;code&gt;qsort_r(...)&lt;/code&gt; (3) was wrapped around platform specific MACROS.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+#if defined(__APPLE__) || defined(__FreeBSD__)
    qsort_r (
              sorted_recordset_ref, 
              num_filtered_records, 
              sizeof(char **), 
              (void*)&amp;amp;grouper_ruleset[0]-&amp;gt;field_offset2,
              gtype-&amp;gt;qsort_comp
            );

+#elif defined(__linux)
+    qsort_r (
+             sorted_recordset_ref, 
+             num_filtered_records, 
+             sizeof(char **), 
+             gtype-&amp;gt;qsort_comp,
+             (void*)&amp;amp;grouper_ruleset[0]-&amp;gt;field_offset2
+            );
+#endif&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;gtype-&amp;gt;qsort_comp&lt;/code&gt; (3) is -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct grouper_type {

+#if defined (__APPLE__) || defined (__FreeBSD__)
   int (*qsort_comp)(
                     void*                           thunk,
                     const void*                     e1,
                     const void*                     e2
                    );
+#elif defined (__linux)
+  int (*qsort_comp)(
+                    const void*                     e1,
+                    const void*                     e2,
+                    void*                           thunk
+                   );
+#endif&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://www.gnu.org/software/libc/manual/html_node/Feature-Test-Macros.html'&gt;feature test macros &lt;span&gt;&lt;code&gt;glibc&lt;/code&gt; manual&lt;/span&gt; &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://sourceware.org/ml/libc-alpha/2008-12/msg00003.html'&gt;&lt;code&gt;qsort_r&lt;/code&gt; argument order &lt;span&gt;&lt;code&gt;glibc&lt;/code&gt; mailing list&lt;/span&gt; &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/grouper_8c.html'&gt;&lt;code&gt;grouper&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>v2.3: it's flexible</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/27/v23-its-flexible"/>
   <updated>2012-04-27T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/27/v23-its-flexible</id>
   <content type="html">&lt;p&gt;Summary: (since after &lt;code&gt;v0.2&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; git show v0.3

tag v0.3
Tagger: Vaibhav Bajpai &amp;lt;contact@vaibhavbajpai.com&amp;gt;
Date:   Wed May 16 18:25:22 2012 +0200
Commit 1c323fa66b9aaaad56ad7c4127b8d187eaf4ec0c

* complete query is read at RUNTIME using JSON-C
* JSON queries are generated using python scripts
* glibc backtrace(...) to print the back trace on errExit(...)
* gracefully exiting when trace cannot be read
* gracefully exiting when JSON query cannot be parsed
* branch thread returns EXIT_FAILURE if either stage returns NULL
* branch thread returns EXIT_SUCCESS on normal exit
* each stage proceeds only when previous returned results
* flow-cat ... | flowy-engine $QUERY -	&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Runtime Query Internals</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/25/runtime-query-internals"/>
   <updated>2012-04-25T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/25/runtime-query-internals</id>
   <content type="html">&lt;p&gt;When reading the &lt;code&gt;JSON&lt;/code&gt; query at RUNTIME, the field offsets of the NetFlow v5 record &lt;code&gt;struct&lt;/code&gt; are read in as a &lt;code&gt;char&lt;/code&gt; pointer. A utility function &lt;code&gt;get_offset(...)&lt;/code&gt; (2) was thus introduced that maps the read offset names to struct offsets.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;size_t
get_offset (
            const char * const name, 
            const struct fts3rec_offsets* const offsets
           ) {
  
  #define CASEOFF(memb)                       \
  if (strcmp(name, #memb) == 0)               \
    return offsets-&amp;gt;memb
  
  CASEOFF(unix_secs);
  CASEOFF(unix_nsecs);
  ...	
		  
  return -1;
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similary the type of each offset and the operation type are also read in as &lt;code&gt;char&lt;/code&gt; pointers. This information is saved and thus used in the engine using an &lt;code&gt;enum&lt;/code&gt; defined in &lt;code&gt;pipeline.h&lt;/code&gt; (1). Therefore, another utility function &lt;code&gt;get_enum(...)&lt;/code&gt; (2) was defined to map this information to the unique enum members.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uint64_t
get_enum(const char * const name) {
  
  #define CASEENUM(memb)                      \
  if (strcmp(name, #memb) == 0)               \
    return memb
  
  CASEENUM(RULE_S1_8);
  CASEENUM(RULE_S1_16);
  ...
  
  CASEENUM(RULE_S2_8);
  CASEENUM(RULE_S2_16);
  ...

  CASEENUM(RULE_ABS);
  CASEENUM(RULE_REL);
  CASEENUM(RULE_NO);
  ...	  

  CASEENUM(RULE_EQ);
  CASEENUM(RULE_NE); 
  ...	  

  CASEENUM(RULE_STATIC);
  CASEENUM(RULE_COUNT);
  ...	  

  CASEENUM(RULE_ALLEN_BF);
  CASEENUM(RULE_ALLEN_AF);
  ...	  
  
  return -1;
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/pipeline_8h.html'&gt;&lt;code&gt;pipeline&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/utils_8c.html'&gt;&lt;code&gt;utils&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Reading Queries at Runtime using json c</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/25/reading-queries-at-runtime-using-json-c"/>
   <updated>2012-04-25T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/25/reading-queries-at-runtime-using-json-c</id>
   <content type="html">&lt;p&gt;The complete query is now read in at runtime. The query is supplied as a &lt;code&gt;JSON&lt;/code&gt; file. The branchsets and each ruleset of the pipeline is a &lt;code&gt;JSON&lt;/code&gt; array. Each array is preceded by the number of items in that array. A sample &lt;code&gt;JSON&lt;/code&gt; query is shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;branchset&amp;quot;: [
    &amp;quot;num_branches&amp;quot;: 2
    {
      &amp;quot;filter&amp;quot;: {
        &amp;quot;num_rules&amp;quot;: 2,
        &amp;quot;ruleset&amp;quot;: [...]
      },

      &amp;quot;grouper&amp;quot;: {
        &amp;quot;num_rules&amp;quot;: 2,
        &amp;quot;ruleset&amp;quot;: [...]
      }

      &amp;quot;aggregation&amp;quot;: {
        &amp;quot;num_rules&amp;quot;: 4,
        &amp;quot;ruleset&amp;quot;: [...]
      },
      
      &amp;quot;groupfilter&amp;quot;: {
        &amp;quot;num_rules&amp;quot;: 1,
        &amp;quot;ruleset&amp;quot;: [...]
      },
    },
    { 
      ...
    }
  ],
  &amp;quot;merger&amp;quot;: {
  &amp;quot;num_rules&amp;quot;: 2,
    &amp;quot;ruleset&amp;quot;: [...]
  },
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;json-c&lt;/code&gt; (1) is used to parse the query read by calling &lt;code&gt;parse_json_query(...)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct json* json_query = parse_json_query(param_data-&amp;gt;query_mmap);&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The structure thus filled looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct json {
  size_t                          num_branches;
  size_t                          num_mrules;
  
  struct json_branch_rules**      branchset;
  struct json_merger_rule**       mruleset;
};&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where each branch rule looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct json_branch_rules {
  size_t                          num_frules;
  size_t                          num_grules;
  size_t                          num_arules;
  size_t                          num_gfrules;
  
  struct json_filter_rule**       fruleset;
  struct json_grouper_rule**      gruleset;
  struct json_aggr_rule**         aruleset;  
  struct json_gfilter_rule**      gfruleset;    
};&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;json_query&lt;/code&gt; is then used to prepare the &lt;code&gt;flowquery&lt;/code&gt;struct used by the stages (2).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct flowquery* fquery = prepare_flowquery(param_data-&amp;gt;trace, json_query);&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Practically, the &lt;code&gt;json_query&lt;/code&gt; is just an intermediate and shouldn&amp;#8217;t be needed. Essentially &lt;code&gt;parse_json_query(...)&lt;/code&gt; should directly fill in and create the &lt;code&gt;flowquery&lt;/code&gt; struct. I see it as a future refactor item.&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://oss.metaparadigm.com/json-c/'&gt;&lt;code&gt;json-c&lt;/code&gt; Library &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://mthesis.vaibhavbajpai.com/post/20901257812/complete-engine-refactor'&gt;&lt;code&gt;flowquery&lt;/code&gt; structs and its descendents &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Generating JSON queries using Python</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/25/generating-json-queries-using-python"/>
   <updated>2012-04-25T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/25/generating-json-queries-using-python</id>
   <content type="html">&lt;p&gt;The &lt;code&gt;JSON&lt;/code&gt; query is verbose and quite cumbersome to manually edit. The Python Parser will eventually emit this intermediate format, so the next logical step is to generate the query from Python. A sample Python script looks like -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class FilterRule: ...
class GrouperRule: ...
class AggregationRule: ...
class GroupFilterRule: ...
class MergerRule: ...

bset = []
bset.append (
              {
               &amp;#39;filter&amp;#39;: {&amp;#39;num_rules&amp;#39;: len(fruleset), &amp;#39;ruleset&amp;#39;: fruleset},
               &amp;#39;grouper&amp;#39;: {&amp;#39;num_rules&amp;#39;: len(gruleset), &amp;#39;ruleset&amp;#39;: gruleset},
               &amp;#39;aggregation&amp;#39;: {&amp;#39;num_rules&amp;#39;: len(aruleset), &amp;#39;ruleset&amp;#39;: aruleset},
               &amp;#39;groupfilter&amp;#39;: {&amp;#39;num_rules&amp;#39;: len(gfruleset), &amp;#39;ruleset&amp;#39;: gfruleset},
              }
            );

query = {
          &amp;#39;num_branches&amp;#39;: len(branchset),
          &amp;#39;branchset&amp;#39;: branchset,
          &amp;#39;merger&amp;#39;: merger
        }

fjson = json.dumps(query, indent=2)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where each &lt;code&gt;ruleset&lt;/code&gt;is a list of Python objects. For instance, &lt;code&gt;fruleset&lt;/code&gt;is a list of &lt;code&gt;FilterRule&lt;/code&gt;objects. At this point, the Python Parser just needs to create each stage rule objects and this script will take care to emit the &lt;code&gt;JSON&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Some example scripts to generate &lt;code&gt;JSON&lt;/code&gt; queries is given in &lt;code&gt;scripts/queries/&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;|-- scripts/
|   |-- queries/
|   |   |-- build-ftp-tcp-session.py*
|   |   |-- build-http-octets.py*
|   |   |-- build-http-tcp-session.py*
|   |   `-- build-https-tcp-session.py*&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Flexible Stages</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/24/flexible-stages"/>
   <updated>2012-04-24T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/24/flexible-stages</id>
   <content type="html">&lt;p&gt;&lt;code&gt;grouper(...)&lt;/code&gt; and &lt;code&gt;groupfilter(...)&lt;/code&gt; only proceed when previous stage returned something.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* grouper */
struct grouper_result*
grouper(...) {

  /* go ahead if there is something to group */
  if (fresult-&amp;gt;num_filtered_records &amp;gt; 0) {...}    
}

/* group filter */
struct groupfilter_result*
groupfilter(...) {

  /* go ahead if there is something to group filter */
  for (int i = 0, j = 0; i &amp;lt; gresult-&amp;gt;num_groups; i++) {...}
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;merger(...)&lt;/code&gt; proceeds only when every branch has non-zero filtered groups. This is achieved using the iterator. &lt;code&gt;iter_init(...)&lt;/code&gt; deallocates and returns &lt;code&gt;NULL&lt;/code&gt; if any one branch has 0 filtered groups. Consequently a check is performed in the &lt;code&gt;merger(...)&lt;/code&gt; to make sure &lt;code&gt;iter&lt;/code&gt; is NOT &lt;code&gt;NULL&lt;/code&gt;before proceeding.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* merger */
struct merger_result*
merger(...) {

  /* initialize the iterator */
  struct permut_iter* iter = iter_init(num_branches, branchset);
  if (iter == NULL)
    return mresult;
  ...
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As a result, some issues were resolved and closed -&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;merger segfault when &lt;code&gt;num_filtered_records&lt;/code&gt; for either branch is 0&lt;/li&gt;

&lt;li&gt;merger segfault when &lt;code&gt;num_filtered_groups&lt;/code&gt; in either branch is 0&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>Graceful Exits on Failure</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/22/graceful-exits-on-failure"/>
   <updated>2012-04-22T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/22/graceful-exits-on-failure</id>
   <content type="html">&lt;p&gt;using glibc &lt;code&gt;backtrace(...)&lt;/code&gt; to print the stack trace on &lt;code&gt;errExit(...)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; bin/engine foo bar
ERROR: open

Stack Trace: 
0   engine                              0x000000010bc891c2 print_trace + 34
1   engine                              0x000000010bc893cb errExit + 395
2   engine                              0x000000010bc898de read_param_data + 174
3   engine                              0x000000010bc8c600 main + 80
4   engine                              0x000000010bc6e054 start + 52&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gracefully exiting when the trace cannot be read/parsed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; bin/engine examples/query-http-tcp-session.json foo
ERROR: open	

Stack Trace: 
...

&amp;gt;&amp;gt; sudo cat /boot/vmlinuz-3.2.0-23-generic | \
   bin/engine examples/query-http-tcp-session.json -

: ftiheader_read(): Warning, bad magic number
: ftiheader_read(): failed
ERROR: ftio_init(...)

Stack Trace: 
...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gracefully exiting when the &lt;code&gt;JSON&lt;/code&gt; query cannot be read/parsed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; bin/engine examples/trace.ft examples/trace.ft
ERROR: json_tokener_parse_ex(...)

Stack Trace: 
...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;branch thread returns &lt;code&gt;EXIT_FAILURE&lt;/code&gt; if either stage returns &lt;code&gt;NULL&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;branch-&amp;gt;filter_result = filter(...);	
if (branch-&amp;gt;filter_result == NULL)
  pthread_exit((void*)EXIT_FAILURE);
  
branch-&amp;gt;grouper_result = grouper(...);
if (branch-&amp;gt;grouper_result == NULL)
  pthread_exit((void*)EXIT_FAILURE);

branch-&amp;gt;gfilter_result = groupfilter(...);
if (branch-&amp;gt;gfilter_result == NULL)
  pthread_exit((void*)EXIT_FAILURE);&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;branch thread returns &lt;code&gt;EXIT_SUCCESS&lt;/code&gt; on normal exit&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void *
branch_start(void *arg) {	  
  ...
  pthread_exit((void*)EXIT_SUCCESS);
}&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Reading Multiple Traces from stdin</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/20/reading-multiple-traces-from-stdin"/>
   <updated>2012-04-20T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/20/reading-multiple-traces-from-stdin</id>
   <content type="html">&lt;p&gt;The engine can now read traces from &lt;code&gt;stdin&lt;/code&gt;.&lt;br /&gt;This means, now we can concatenate multiple traces using &lt;code&gt;flow-cat&lt;/code&gt; and then pipe them in to the engine for processing -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;flow-cat $TRACE[s] | bin/engine $QUERY -&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A typical query to find all the HTTP (over TCP) sessions for April resulted in 285 streams and took around 2 minutes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; time flow-cat /Netflow/ft-data/2012/2012-04 | \
   bin/engine examples/query-http-tcp-session.json -

No. of Streams: 285
--------------- 
...&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>v2.2: it's robust</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/18/v22-its-robust"/>
   <updated>2012-04-18T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/18/v22-its-robust</id>
   <content type="html">&lt;p&gt;Summary: (since after &lt;code&gt;v0.1&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git show v0.2

tag v0.2
Tagger: Vaibhav Bajpai &amp;lt;contact@vaibhavbajpai.com&amp;gt;
Date:   Wed Apr 18 13:24:16 2012 +0200    
Commit 2c571f80cd076172cbd00ef7f9976b88cb44b425

* complete engine refactor.
* complete engine profiling (no memory leaks).
* issues closed:
    - greedily deallocating non-filtered records in `O(n)` before `merger(...)`.
    - resolved a grouper segfault when NO records got filtered.
    - all records are grouped into 1 group when no grouping rule specified.
    - aggregation on common fields touched by filter/grouper rules is ignored.
    - no `uintX_t` assumptions for field offsets.
    - rules are clubbed together and assigned using a loop.
    - function parameters are as minimum as required.
    - function parameters are safe using `[const]` ptr and ptr to `[const]`.
    - lazy `rule-&amp;gt;func(...)` assignment when the stage is entered.	&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Lazy Comparator Assignments</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/18/lazy-comparator-assignments"/>
   <updated>2012-04-18T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/18/lazy-comparator-assignments</id>
   <content type="html">&lt;p&gt;There are dedicated comparator functions for each &lt;code&gt;uintX_t&lt;/code&gt; type of the field offset. Up until now, the choice for the function was made using a single function, &lt;code&gt;assign_fptr(...)&lt;/code&gt; (1) which was called before the start of the pipeline to ensure all function pointers point to the right functions of each stage. Here is small snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;assign_fptr(struct flowquery *fquery) {

  for (int i = 0; i &amp;lt; fquery-&amp;gt;num_branches; i++) {

    struct branch* branch = fquery-&amp;gt;branchset[i];    
    
    /* for loop for the filter */
    for (int j = 0; j &amp;lt; branch-&amp;gt;num_filter_rules; j++) {…}
    
    /* for loop for the grouper */
    for (int j = 0; j &amp;lt; branch-&amp;gt;num_grouper_rules; j++) {…}    
    
    /* for loop for the group-aggregation */
    for (int j = 0; j &amp;lt; branch-&amp;gt;num_aggr_rules; j++) {…}
    
    /* for loop for the group-filter */
    for (int j = 0; j &amp;lt; branch-&amp;gt;num_gfilter_rules; j++) {…}	
  }
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function is quite computationally expensive, since it falls through a HUGE switch statement to determine the function of right type. It is not guaranteed that given the type of the query and trace, the program will eventually go through each stage of the pipeline. It is also possible that the program exits before, because there is nothing more for the next stage to compute. As such the function pointers should be SET only from within the stage for the current stage. Here is a snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;assign_filter_func(struct filter_rule* const frule) {...}
assign_grouper_func(struct grouper_rule* const grule) {...}  
assign_aggr_func(struct aggr_rule* const arule) {...}
assign_gfilter_func(struct gfilter_rule* const gfrule) {...}
assign_merger_func(struct merger_rule* const mrule) {...}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each of these functions are called from their respective stages just before when the comparison is required to be performed. As a result, we save the computation time wasted in setting the function pointer for stage X if X is never executed.&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/auto__assign_8c.html'&gt;&lt;code&gt;auto_assign&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Flexible Grouper</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/18/flexible-grouper"/>
   <updated>2012-04-18T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/18/flexible-grouper</id>
   <content type="html">&lt;p&gt;The &lt;code&gt;grouper(...)&lt;/code&gt; (1) call was plagued with hardcoded &lt;code&gt;uint32_t&lt;/code&gt; type assumption on the field offset being used to make grouper rule comparisons. The function now internally calls &lt;code&gt;get_gtype(...)&lt;/code&gt; to fall through a switch case to determine the type of the field offset at RUNTIME. Here is a snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct grouper_type* get_gtype(uint64_t op) { 
  ...
  switch (op) {
  
    case RULE_S2_8:
      gtype-&amp;gt;qsort_comp = comp_uint8_t;
      gtype-&amp;gt;bsearch = bsearch_uint8_t;
      gtype-&amp;gt;alloc_uniqresult = alloc_uniqresult_uint8_t;
      gtype-&amp;gt;get_uniq_record = get_uniq_record_uint8_t;      
      gtype-&amp;gt;dealloc_uniqresult = dealloc_uniqresult_uint8_t;

      break;
    case RULE_S2_16:
      ...
      break;
      
    case RULE_S2_32:
      ...
      break;
      
    case RULE_S2_64:
      ...
      break;
  }
  return gtype;
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point I do not think I have any assumptions on any field offset for any pipeline stage. As such experimentation on different style of queries should now work and is the next item on the list to investigate.&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/grouper_8h_source.html'&gt;&lt;code&gt;grouper&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Few Closed Issues</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/11/few-closed-issues"/>
   <updated>2012-04-11T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/11/few-closed-issues</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Greedily deallocating non-filtered records.&lt;/p&gt;

&lt;p&gt;Each branch of the pipeline is executed by a separate thread. Since each branch does NOT have a copy of the trace but points to the original records, individual branches CANNOT free the records that were not filtered by them, since they could be filtered by some other branch. As a consequence, the records that were not filtered by any branch can only be free&amp;#8217;d once all threads join the &lt;code&gt;main(…)&lt;/code&gt;, ie. before calling the &lt;code&gt;merger(…)&lt;/code&gt;. The following implementation is costly and runs in worst case &lt;code&gt;O(nkm)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of records in the trace, &lt;code&gt;k&lt;/code&gt; is the number of branches, and &lt;code&gt;m&lt;/code&gt; is the number of filtered records in each branch.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-  for (int i = 0; i &amp;lt; param_data-&amp;gt;trace-&amp;gt;num_records; i++) {
-    bool if_filtered_record = false;
-    char* record = param_data-&amp;gt;trace-&amp;gt;records[i];
-    for (int j = 0; j &amp;lt; fquery-&amp;gt;num_branches; j++) {
-      struct branch_info* branch = fquery-&amp;gt;branchset[j];        
-      for (int k = 0; k &amp;lt; branch-&amp;gt;filter_result-&amp;gt;num_filtered_records; k++) {
-        char* filtered_record = branch-&amp;gt;filter_result-&amp;gt;filtered_recordset[k];
-	  ...
-    }
-    if (!if_filtered_record) {
-      free(record); record = NULL;
-      param_data-&amp;gt;trace-&amp;gt;records[i] = NULL;      
-    }

    struct merger_result* mresult = merger(...)
    ...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instead, it would be better to extend the trace structure to allow a flag that stores meta-information about the record.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    struct ft_data {
-     char**                          records;
+     struct record**                 recordset;
+     int                             num_records;
    };
 
+   struct record {
+     char*                           record;
+     bool                            if_filtered;
+   };	&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, the same can free the non-filtered records in worst case &lt;code&gt;O(n)&lt;/code&gt; time where &lt;code&gt;n&lt;/code&gt; is the number of records in the trace.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+  for (int i = 0; i &amp;lt; param_data-&amp;gt;trace-&amp;gt;num_records; i++) {      
+    struct record* recordinfo = param_data-&amp;gt;trace-&amp;gt;recordset[i];
+    if (recordinfo-&amp;gt;if_filtered == false)
+      free(recordinfo-&amp;gt;record); recordinfo-&amp;gt;record = NULL;
   }&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Resolved a Grouper segfault when NO records got filtered.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   struct filter_result* fresult = filter(...);
+  if (fresult-&amp;gt;num_filtered_records == 0)
+    pthread_exit(NULL);
      
   struct grouper_result* gresult = grouper(...);  &lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>Complete Execution Engine Refactor</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/11/complete-execution-engine-refactor"/>
   <updated>2012-04-11T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/11/complete-execution-engine-refactor</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The complete project flow is reorganized to increase readability (1, 2)&lt;/p&gt;

&lt;p&gt;&lt;img alt='parse_cmdline_args(…)' src='http://i.imgur.com/bwNbS.png' /&gt;&lt;br /&gt;&lt;img alt='parse_json_query(…))' src='http://i.imgur.com/fGEHp.png' /&gt;&lt;br /&gt;&lt;img alt='prepare_flowquery(…)' src='http://i.imgur.com/o0aNo.png' /&gt;&lt;br /&gt;&lt;img alt='read_param_data(…)' src='http://i.imgur.com/bNZyn.png' /&gt;&lt;br /&gt;&lt;img alt='filter(…)' src='http://i.imgur.com/boMWR.png' /&gt;&lt;br /&gt;&lt;img alt='get_grouper_intermediate(…)' src='http://i.imgur.com/0ajML.png' /&gt;&lt;br /&gt;&lt;img alt='grouper_aggregations(…)' src='http://i.imgur.com/l9wcn.png' /&gt;&lt;br /&gt;&lt;img alt='grouperfilter(…)' src='http://i.imgur.com/nI5EY.png' /&gt;&lt;br /&gt;&lt;img alt='merger(…)' src='http://i.imgur.com/jR86d.png' /&gt; &lt;br /&gt;&lt;img alt='ungrouper(…)' src='http://i.imgur.com/5CTgc.png' /&gt;&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Query rules are clubbed in &lt;code&gt;X_ruleset&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; is &lt;code&gt;filter&lt;/code&gt;, &lt;code&gt;grouper&lt;/code&gt;, &lt;code&gt;gfilter&lt;/code&gt;, &lt;code&gt;merger&lt;/code&gt; (3)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;flowquery {...}&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct flowquery {  
  size_t                          num_branches;  
  struct branch**                 branchset;  
  			  
  size_t                          num_merger_rules;  
  struct merger_rule**            mruleset;
  
  struct merger_result*           merger_result; 
  struct ungrouper_result*        ungrouper_result;
};	&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;branch {...}&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct branch {

  /*---------------------------------------------------------------*/  
  /*                          inputs                               */
  /*---------------------------------------------------------------*/  
  ...		
  size_t                          num_filter_rules;
  size_t                          num_grouper_rules;
  size_t                          num_aggr_rules;
  size_t                          num_gfilter_rules;
  
  struct filter_rule**            filter_ruleset;  
  struct grouper_rule**           grouper_ruleset;
  struct aggr_rule**              aggr_ruleset;  
  struct gfilter_rule**           gfilter_ruleset;  
  /*---------------------------------------------------------------*/  

  /*---------------------------------------------------------------*/  
  /*                          output                               */
  /*---------------------------------------------------------------*/  
  struct filter_result*           filter_result;
  struct grouper_result*          grouper_result;
  struct groupfilter_result*      gfilter_result;
  /*---------------------------------------------------------------*/  

};&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Each stage returns &lt;code&gt;X_result&lt;/code&gt; &lt;code&gt;X&lt;/code&gt; is &lt;code&gt;filter&lt;/code&gt;, &lt;code&gt;grouper&lt;/code&gt;, &lt;code&gt;gfilter&lt;/code&gt;, &lt;code&gt;merger&lt;/code&gt;, &lt;code&gt;ungrouper&lt;/code&gt; (3).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;filter(...)&lt;/code&gt; returns &lt;code&gt;filter_result&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct filter_result* filter(...) {...}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct filter_result {          
  size_t                          num_filtered_records;
  char**                          filtered_recordset;  
};&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;grouper(...)&lt;/code&gt; returns &lt;code&gt;grouper_result&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct grouper_result* grouper(...) {...}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct grouper_result {
  size_t                          num_unique_records;  
  char**                          sorted_recordset;
  char**                          unique_recordset;
  
  size_t                          num_groups;  
  struct group**                  groupset;
};		&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;groupfilter(...)&lt;/code&gt; returns &lt;code&gt;groupfilter_result&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct groupfilter_result* groupfilter(...) {...}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct groupfilter_result {
  size_t                          num_filtered_groups;  
  struct group**                  filtered_groupset;
};&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;merger(...)&lt;/code&gt; returns &lt;code&gt;merger_result&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct merger_result* merger(...) {...}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct merger_result {
  size_t                          num_group_tuples;  
  size_t                          total_num_group_tuples;
  struct group***                 group_tuples;
};&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;ungrouper(...)&lt;/code&gt; returns &lt;code&gt;ungrouper_result&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct ungrouper_result* ungrouper(...) {...}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct ungrouper_result {
  size_t                          num_streams;    
  struct stream**                 streamset;
};&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Added &lt;code&gt;echo.{h,c}&lt;/code&gt; for verbose and debug modes (4)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;with atleast &lt;code&gt;--verbose=1&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img alt='echo_filter' src='http://i.imgur.com/1AGfj.png' /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;with atleast &lt;code&gt;--verbose=2&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img alt='echo_grouper' src='http://i.imgur.com/sGZff.png' /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt='echo_group_aggr' src='http://i.imgur.com/IjdHh.png' /&gt;&lt;br /&gt;&lt;img alt='echo_gfilter' src='http://i.imgur.com/4JqOp.png' /&gt;&lt;br /&gt;&lt;img alt='echo_merger' src='http://i.imgur.com/aKQs0.png' /&gt;&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;always:&lt;/p&gt;

&lt;p&gt;&lt;img alt='echo_results' src='http://i.imgur.com/guxpg.png' /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;X_ruleset&lt;/code&gt; are deallocated as soon as &lt;code&gt;X&lt;/code&gt; stage returns.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;grouper(...)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; branch-&amp;gt;grouper_result = grouper(...); 
 if (branch-&amp;gt;grouper_result == NULL)
   errExit(&amp;quot;grouper(...) returned NULL&amp;quot;);
 else {
 			    
   /* free filter rules */
   ...		
   /* free grouper rules */
   ...				    
   /* free grouper aggregation rules */
   ...		
 }  &lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;groupfilter(...)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;branch-&amp;gt;gfilter_result = groupfilter(...);
if (branch-&amp;gt;gfilter_result == NULL)
  errExit(&amp;quot;groupfilter(...) returned NULL&amp;quot;);
else {
   
  /* free group filter rules */
  ...
}&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;merger(...)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fquery-&amp;gt;merger_result = merger(...); 
  
if (fquery-&amp;gt;merger_result == NULL)
  errExit(&amp;quot;merger(...) returned NULL&amp;quot;);
else {
    
    /* free merger rules */	
    ... 
}    &lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;References:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/branch_8c.html'&gt;&lt;code&gt;branch&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/structflowquery.html'&gt;&lt;code&gt;flowquery&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(4) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/echo_8h_source.html'&gt;&lt;code&gt;echo&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Complete Execution Engine Profiling</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/04/11/complete-execution-engine-profiling"/>
   <updated>2012-04-11T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/04/11/complete-execution-engine-profiling</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Before:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git checkout v0.1
$ valgrind bin/flowy-engine bin/traces-long.ft bin/query.json

==19000== 
==19000== HEAP SUMMARY:
==19000== in use at exit: 131,519 bytes in 1,182 blocks
==19000== total heap usage: 2,609 allocs, 1,427 frees, 1,631,199 bytes allocs
==19000== 
==19000== LEAK SUMMARY:
==19000== definitely lost: 6,912 bytes in 472 blocks
==19000== indirectly lost: 0 bytes in 0 blocks
==19000== possibly lost: 0 bytes in 0 blocks
==19000== still reachable: 124,607 bytes in 710 blocks
==19000== suppressed: 0 bytes in 0 blocks
==19000== Rerun with --leak-check=full to see details of leaked memory
==19000== 
==19000== For counts of detected and suppressed errors, rerun with: -v
==19000== Use --track-origins=yes to see where uninitialised values come from
==19000== ERROR SUMMARY: 75 errors from 10 contexts (suppressed: 1 from 1)&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;After:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git checkout master
$ valgrind bin/flowy-engine bin/traces-long.ft bin/query.json

==19164== 
==19164== HEAP SUMMARY:
==19164== in use at exit: 20,228 bytes in 37 blocks
==19164== total heap usage: 3,646 allocs, 3,609 frees, 1,647,767 bytes allocs
==19164== 
==19164== LEAK SUMMARY:
==19164== definitely lost: 0 bytes in 0 blocks
==19164== indirectly lost: 0 bytes in 0 blocks
==19164== possibly lost: 0 bytes in 0 blocks
==19164== still reachable: 20,228 bytes in 37 blocks
==19164== suppressed: 0 bytes in 0 blocks
==19164== Rerun with --leak-check=full to see details of leaked memory
==19164== 
==19164== For counts of detected and suppressed errors, rerun with: -v
==19164== Use --track-origins=yes to see where uninitialised values come from
==19164== ERROR SUMMARY: 300 errors from 6 contexts (suppressed: 1 from 1)	&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;20kB&lt;/code&gt; created and still living blocks are due to the following libraries:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;dyld&lt;/code&gt;: all 81 mallocs have these common calls:&lt;/p&gt;

&lt;p&gt;&lt;img alt='dyld' src='http://i.stack.imgur.com/KgXih.png' /&gt;&lt;/p&gt;

&lt;p&gt;On GNU/Linux &lt;code&gt;dyld&lt;/code&gt; would be replaced by &lt;code&gt;dlopen&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;{libsystem_c, libsystem_notify, libdispatch}.dylib&lt;/code&gt;: all 10 mallocs have these common calls:&lt;/p&gt;

&lt;p&gt;&lt;img alt='localtime' src='http://i.stack.imgur.com/iIXOH.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;localtime(...)&lt;/code&gt; defined in &lt;code&gt;time.h&lt;/code&gt; uses &lt;code&gt;tzset(...)&lt;/code&gt; to initialize and return me a &lt;code&gt;struct tm*&lt;/code&gt; which I shouldn&amp;#8217;t &lt;code&gt;free&lt;/code&gt; myself because I did not allocate it. They are apparently not my fault. The Mac OS X kernel will (like any Unix-like kernel) recover that memory when the process exits anyway.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>v2.1: it works</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/26/v21-it-works"/>
   <updated>2012-03-26T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/26/v21-it-works</id>
   <content type="html">&lt;p&gt;The complete pipeline now works for the first time, tagged as &lt;code&gt;v0.1&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git show v0.1

tag v0.1		
Tagger: Vaibhav Bajpai &amp;lt;contact@vaibhavbajpai.com&amp;gt;
Date:   Fri Apr 6 19:07:49 2012 +0200	
Commit a8a67a13aa07f671d21d062537a2ef17e58dcc07
...

* reverse engineered parser to generate UML.
* froze requirements to allow single step installation of the python parser.
* doxygen documentation of the engine.
* prelim JSON parsing framework for the parser and engine.
* replaced GNU99 extensions dependent code with c99.
* resolved numerous segfaults in grouper and merger.
* generated group aggregations as a separate (cooked) NetFlow v5 record.
* flexible group aggregations with no uintX_t assumptions on field offsets.
* first-ever group filter implementation.
* reorganized the src/ directory structure
* enabled multiple verbosity levels in the engine.
* first-ever merger implementation.
* flexible filters and group filters with no uintX_t assumptions on field offsets.
* first-ever ungrouper implementation.&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Ungrouper Implementation</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/26/ungrouper-implementation"/>
   <updated>2012-03-26T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/26/ungrouper-implementation</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;added &lt;code&gt;ungrouper.{h,c}&lt;/code&gt; (1)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;extended the &lt;code&gt;flowquery&lt;/code&gt; struct to keep information coming from the ungrouper (2)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  struct flowquery {
    struct group*** group_tuples;
    size_t num_group_tuples;
    size_t total_num_group_tuples;
+   struct stream** streamset;
+ };
+
+ struct stream{
+   char ** recordset;
+   size_t num_records;
+ };&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;given the &lt;code&gt;group_tuples&lt;/code&gt; the ungrouper returns a set of stream of flow records (3).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fquery-&amp;gt;streamset = ungrouper(
                              fquery-&amp;gt;group_tuples,
                              fquery-&amp;gt;num_group_tuples
                             );&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The ungrouper returns as many streams as there are number of matched group tuples. An example is given below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ bin/flowy-engine bin/traces-long.ft bin/query.json

No. of Streams: 2
----------------- 

No. of Records in Stream (1): 24 

... Sif   SrcIPaddress    SrcP  DIf   DstIPaddress    DstP  ... 
... 0     192.168.0.135   56225 0     216.46.94.66    80    ... 
... 0     216.46.94.66    80    0     192.168.0.135   56228 ... 

No. of Records in Stream (2): 62 

... Sif   SrcIPaddress    SrcP  DIf   DstIPaddress    DstP  ... 
... 0     192.168.0.135   56241 0     209.84.12.126   80    ... 
... 0     209.84.12.126   80    0     192.168.0.135   56240 ...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each stream represents a connection between a &lt;code&gt;srcIP&lt;/code&gt; and &lt;code&gt;dstIP&lt;/code&gt; where the traffic is being carried over &lt;code&gt;port 80&lt;/code&gt; The flow records returned as a part of a stream are not ordered according to their timestamps and is a future work item.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/ungrouper_8c.html'&gt;&lt;code&gt;ungrouper&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/pipeline_8h_source.html'&gt;&lt;code&gt;pipeline&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Flexible Group Filters and Aggregations</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/26/flexible-group-filters-and-aggregations"/>
   <updated>2012-03-26T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/26/flexible-group-filters-and-aggregations</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;gfilter_rule&lt;/code&gt; now takes in a &lt;code&gt;uint_X&lt;/code&gt; RULE when mapping functions (1)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  struct gfilter_rule gfilter_branch1[1] = {
-   {trace_data-&amp;gt;offsets.dPkts, 200, 0, RULE_GT, NULL}
+   {trace_data-&amp;gt;offsets.dPkts, 200, 0, RULE_GT | RULE_S1_32, NULL}
  };&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The additional RULE is used to map to a function that knows the type of the offset at RUNTIME (2).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  switch (binfos[i].gfilter_rules[j].op) {
-   case RULE_EQ:
-     binfos[i].gfilter_rules[j].func = gfilter_eq;
+   case RULE_EQ | RULE_S1_32:
+     binfos[i].gfilter_rules[j].func = gfilter_eq_uint32_t;
+   break;
  ...
  }&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The additional switch cases and comparison functions are automatically generated using &lt;code&gt;fun_gen.py&lt;/code&gt; (3).&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;removed &lt;code&gt;uintX_t&lt;/code&gt; assumptions from grouper aggregations&lt;/p&gt;

&lt;p&gt;The aggregation function needs to know the type of the offsets used previously in the filter and grouper rules to be able to fill in common fields in its cooked v5 group aggregation record. As a result a &lt;code&gt;get_aggr_fptr(…)&lt;/code&gt; function was defined that takes in those previous rules to fall through a switch to return a function pointer to an aggregation function of the correct type (2).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  switch (op) {
+   case RULE_EQ | RULE_S1_8:
+   case RULE_NE | RULE_S1_8:
+   case RULE_GT | RULE_S1_8:
    ...
+     aggr_function = aggr_static_uint8_t;
+     break;
  }&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This aggregation function is then later used to fill in the common fields (4). An example using the filter rules is given below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct aggr (*aggr_function)(
                              char **records,
                              char *group_aggregation,
                              size_t num_records,
                              size_t field_offset,
                              bool if_aggr_common
                            ) = NULL;

aggr_function = get_aggr_fptr( binfo-&amp;gt;filter_rules[i].op );    

(*aggr_function)(
                  group-&amp;gt;members,
                  group_aggregation,
                  group-&amp;gt;num_members, 
                  field_offset, 
                  TRUE
                );&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A similar call is made for the grouper rules as well. The additional switch cases and comparison functions are automatically generated using &lt;code&gt;fun_gen.py&lt;/code&gt; (3)&lt;/p&gt;

&lt;p&gt;The idea of returning a function pointer from a function makes me question if I am trying to write LISP in C? A quick google search led me to (5)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/auto__assign_8c.html'&gt;&lt;code&gt;auto_assign&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/fun__gen_8py.html'&gt;&lt;code&gt;fun_gen&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(4) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/grouper_8c.html'&gt;&lt;code&gt;grouper&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(5) &lt;a href='http://en.wikipedia.org/wiki/Greenspun&amp;apos;s_tenth_rule'&gt;greenspun&amp;#8217;s tenth rule, wikipedia &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Clubbing Together the Hardcoded Rules</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/26/clubbing-together-the-hardcoded-rules"/>
   <updated>2012-03-26T00:00:00+02:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/26/clubbing-together-the-hardcoded-rules</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;clubbed number of rules into one place in (1)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* this should go away once the rules come from the JSON */		
#define NUM_BRANCHES 2
#define NUM_FILTER_RULES_BRANCH1 1
#define NUM_FILTER_RULES_BRANCH2 1
#define NUM_GROUPER_RULES_BRANCH1 2
#define NUM_GROUPER_RULES_BRANCH2 2
#define NUM_GROUPER_AGGREGATION_RULES_BRANCH1 4
#define NUM_GROUPER_AGGREGATION_RULES_BRANCH2 4
#define NUM_GROUP_FILTER_RULES_BRANCH1 1
#define NUM_GROUP_FILTER_RULES_BRANCH2 1
#define NUM_MERGER_RULES 2        &lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Instead of manually filling up structs of each branch as shown below: &lt;span&gt;2&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-  binfos[0].branch_id = 0;
-  binfos[0].filter_rules = filter_rules_branch1;
-  binfos[0].num_filter_rules = 1;
   ...
   		
-  binfos[1].branch_id = 1;
-  binfos[1].filter_rules = filter_rules_branch2;
-  binfos[1].num_filter_rules = 1;
   ...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The number of branches and rules come from &lt;code&gt;flowy.h&lt;/code&gt; and the code now loops through the rules to assign values (2).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+  /* rules for each branch */
+  for (int i = 0; i &amp;lt; fquery-&amp;gt;num_branches; i++) {
   
+    struct filter_rule* frule = calloc(fquery-&amp;gt;branches[i].num_filter_rules, 
+                                       sizeof(struct filter_rule));    
+    for (int j = 0; j &amp;lt; fquery-&amp;gt;branches[i].num_filter_rules; j++) {
+      ...
+    }
+  ...		  &lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Rules are still hardcoded but now they are in one place. It will make debugging and transitioning to &lt;code&gt;JSON&lt;/code&gt; queries easier.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8h_source.html'&gt;&lt;code&gt;flowy.h&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy.c&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Refactoring the Execution Engine</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/19/refactoring-the-execution-engine"/>
   <updated>2012-03-19T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/19/refactoring-the-execution-engine</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;moved &lt;code&gt;branch_start(…)&lt;/code&gt; function (previously in &lt;code&gt;main(…)&lt;/code&gt;) to &lt;code&gt;branch.{h,c}&lt;/code&gt; (1)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;moved filter stage code to newly created &lt;code&gt;filter.{h,c}&lt;/code&gt; (2)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;renamed &lt;code&gt;grouper_fptr.{h,c}&lt;/code&gt; → &lt;code&gt;grouper.{h,c}&lt;/code&gt; (3)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;moved groupfilter stage code to newly created &lt;code&gt;groupfilter.{h,c}&lt;/code&gt; (4)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;renamed &lt;code&gt;merger_fptr.{h,c}&lt;/code&gt; → &lt;code&gt;merger.{h,c}&lt;/code&gt; (5)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;moved &lt;code&gt;iterate.{h,c}&lt;/code&gt; code (used by merger) to &lt;code&gt;utils.{h,c}&lt;/code&gt; (6)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;removed number of undefined function prototypes from &lt;code&gt;utils.h&lt;/code&gt; (6)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct bsearch_handle *
tree_create_uintX_t(
                    char **records, 
                    size_t num_records, 
                    unsigned short field_offset
                   );
char **
tree_find_uintX_t( 
                  struct bsearch_handle *handle,
                  char *record, 
                  unsigned short field_offset
                 );
void 
tree_destroy(struct bsearch_handle *handle);&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;X = {8, 16, 32, 64}&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;reorganized the whole engine&amp;#8217;s &lt;code&gt;src&lt;/code&gt; directory structure:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;├── auto-generated/
│   ├── auto_assign.c
│   ├── auto_assign.h
│   ├── auto_comps.c
│   ├── auto_comps.h
│   └── fun_gen.py*
├── bin/
│   ├── filter-poop.py*
│   ├── flowy-engine*
│   ├── query.json
│   ├── traces-long.ft*
│   └── traces.ft*
├── helpers/
│   ├── error_handlers.c
│   ├── error_handlers.h
│   ├── utils.c
│   └── utils.h
├── pipeline/
│   ├── branch/
│   │   ├── branch.c
│   │   ├── branch.h
│   │   ├── filter.c
│   │   ├── filter.h
│   │   ├── grouper.c
│   │   ├── grouper.h
│   │   ├── groupfilter.c
│   │   └── groupfilter.h
│   ├── merger.c
│   ├── merger.h
│   └── pipeline.h
├── Doxyfile
├── Makefile
├── README.md
├── base.c
├── base.h
├── flowy.c
├── flowy.h
├── ftreader.c
└── ftreader.h&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/branch_8h.html'&gt;&lt;code&gt;branch&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/filter_8h.html'&gt;&lt;code&gt;filter&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/grouper_8h.html'&gt;&lt;code&gt;grouper&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(4) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/groupfilter_8h.html'&gt;&lt;code&gt;groupfilter&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(5) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/merger_8h.html'&gt;&lt;code&gt;merger&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(6) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/utils_8h.html'&gt;&lt;code&gt;utils&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Merger Internals</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/19/merger-internals"/>
   <updated>2012-03-19T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/19/merger-internals</id>
   <content type="html">&lt;p&gt;The pseudocode for the merger looks like: (1)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;get_module_output_stream(module m) {
  (branch_1, branch_2, ..., branch_n) = get_input_branches(m);
  for each g_1 in group_records(branch_1)
    for each g_2 in group_records(branch_2)
      ...
        ...
           for each g_n in group_records(branch_n)
              if match(g_1, g_2, ..., g_n, rules(m))
                 output.add(g_1, g_2,..., g_n);
  return output;
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Implementing this pseudocode in &lt;code&gt;C&lt;/code&gt; is not straightforward, since the level of nesting actually depends on the number of branches, and is therefore not known until RUNTIME when is passed through the query.&lt;/p&gt;

&lt;p&gt;As such we need to implement a utility that can provide all possible permutations of &lt;code&gt;N&lt;/code&gt;-tuple group record IDs that we can use to make a match, where &lt;code&gt;N&lt;/code&gt; is the number of branches.&lt;/p&gt;

&lt;p&gt;As such, we initialize an iterator passing it the number of branches, and information about each branch. Then, we iterate over until the iterator returns &lt;code&gt;FALSE&lt;/code&gt;. (2) A sample code to print all possible groupID permutation tuples is shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* initialize the iterator */
struct permut_iter *iter = iter_init(binfo_set, num_branches);

/* iterate over all permutations */
unsigned int index = 0;
while(iter_next(iter)) {
  index++
  for (int j = 0; j &amp;lt; num_branches; j++) {
    /* first item */
    if(j == 0)
      printf(&amp;quot;\n%d: (%zu &amp;quot;, index, iter-&amp;gt;filtered_group_tuple[j]);
    /* last item */
    else if(j == num_branches -1)
      printf(&amp;quot;%zu)&amp;quot;, iter-&amp;gt;filtered_group_tuple[j]);
    else
      printf(&amp;quot;%zu &amp;quot;, iter-&amp;gt;filtered_group_tuple[j]);
  }
}

/* free the iterator */
iter_destroy(iter);&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output gives all possible permutations, which we later use to try to make a match. Here, the number of filtered groups passed to merger where: &lt;code&gt;(b1, b2, b3) = (3, 2, 2)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1: (1 1 1)
2: (1 1 2)
3: (1 2 1)
4: (1 2 2)
5: (2 1 1)
6: (2 1 2)
7: (2 2 1)
8: (2 2 2)
9: (3 1 1)
10: (3 1 2)
11: (3 2 1)
12: (3 2 2)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='https://svn.eecs.jacobs-university.de/svn/eecs/archive/msc-2009/vmarinov.pdf'&gt;vmarinov&amp;#8217;s masters thesis &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/utils_8c.html'&gt;&lt;code&gt;merger&lt;/code&gt; utilities &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Merger Implementation</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/19/merger-implementation"/>
   <updated>2012-03-19T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/19/merger-implementation</id>
   <content type="html">&lt;p&gt;The engine can now merge the groups from different branches according to a merging criteria. For example, a simple query to merge groups looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;merger m {
  module m1 {
    branches A, B
    A.srcip = B.dstip
    A.dstip = B.srcip
  }
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;such a merging rule reflects in the engine as (1):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct merger_rule mfilter[2] = {
  {
    &amp;amp;binfos[0], trace_data-&amp;gt;offsets.srcaddr, 
    &amp;amp;binfos[1], trace_data-&amp;gt;offsets.dstaddr, 
    RULE_EQ | RULE_S1_32 | RULE_S2_32, 0, NULL
  },

  {
    &amp;amp;binfos[0], trace_data-&amp;gt;offsets.dstaddr, 
    &amp;amp;binfos[1], trace_data-&amp;gt;offsets.srcaddr,
    RULE_EQ | RULE_S1_32 | RULE_S2_32, 0, NULL
  },
};&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the rule maps to a specific merger function using a &lt;code&gt;switch&lt;/code&gt; case (2):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* for loop for the merger */
for (int j = 0; j &amp;lt; fquery-&amp;gt;num_merger_rules; j++) {
  switch (fquery-&amp;gt;mrules[j].op) {
    ...
    case RULE_EQ | RULE_S1_32 | RULE_S2_32:
      fquery-&amp;gt;mrules[j].func = merger_eq_uint32_t_uint32_t;
      break;
    ...
  }
}    &lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The merger functions are auto-generated using a python script &lt;code&gt;fun-gen.py&lt;/code&gt; (3).&lt;/p&gt;

&lt;p&gt;This is how the result looks:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ ./flowy-engine traces-long.ft query.json --verbose=1

No. of Merged Groups: 2 (Tuples)

... Sif   SrcIPaddress    SrcP  DIf   DstIPaddress    DstP  ... 

... 0     192.168.0.135   0     0     216.46.94.66    80    ... 
... 0     216.46.94.66    80    0     192.168.0.135   0     ... 

... 0     192.168.0.135   0     0     209.84.12.126   80    ... 
... 0     209.84.12.126   80    0     192.168.0.135   0     ... &lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All the permutation of group tuples checked for a match can be seen by increasing the verbosity level.&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/auto__assign_8c.html'&gt;&lt;code&gt;auto_assign&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/namespacefun__gen.html'&gt;&lt;code&gt;fun_gen&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Group Filter Implementation</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/19/group-filter-implementation"/>
   <updated>2012-03-19T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/19/group-filter-implementation</id>
   <content type="html">&lt;p&gt;The engine can now filter the groups according to a filtering criteria.&lt;br /&gt;For example, a simple query to filter groups with &lt;code&gt;sum(pkts) &amp;gt; 200&lt;/code&gt; looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grouper g {
  module g1 {
    srcip = srcip
    dstip = dstip
  }
  aggregate srcip, dstip, sum(packets) as pkts
}

groupfilter gf {
  pkts &amp;gt; 200
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;such a filtering rule reflects in the engine as (1):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct gfilter_rule gfilter_branch2[1] = {
  {trace_data-&amp;gt;offsets.dPkts, 200, 0, RULE_GT, NULL}
};&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the rule maps to a specific group-filter function using a &lt;code&gt;switch&lt;/code&gt; case (2):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* for loop for the group-filter */
  for (int j = 0; j &amp;lt; binfos[i].num_gfilter_rules; j++) {
    switch (binfos[i].gfilter_rules[j].op) {
      ...
      case RULE_GT:
        binfos[i].gfilter_rules[j].func = gfilter_gt;
        break;
      ...
    }
  }&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The group-filter functions are auto-generated using a python script &lt;code&gt;fun-gen.py&lt;/code&gt; (3).&lt;/p&gt;

&lt;p&gt;This is how the result looks:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ ./flowy-engine traces-long.ft query.json --debug
...

No. of Filtered Groups: 5 (Aggregations)

...	   SrcIPaddress   	...     DstIPaddress      Sum(Pkts)
...	   216.46.94.66    	...  	192.168.0.135     345
...	   209.84.12.126   	...  	192.168.0.135     475
...	   207.171.166.252 	...  	192.168.0.135     212&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/auto__assign_8c.html'&gt;&lt;code&gt;auto_assign&lt;/code&gt; references &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/namespacefun__gen.html'&gt;&lt;code&gt;fun_gen&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Flexible Group Aggregations</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/19/flexible-group-aggregations"/>
   <updated>2012-03-19T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/19/flexible-group-aggregations</id>
   <content type="html">&lt;p&gt;The group aggregation functions were hardcoded in the &lt;code&gt;group_aggr&lt;/code&gt; struct (1, 2). The functions are now replaced with RULES that map to a specific aggregation function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct grouper_aggr group_aggr_branch1[4] = {
-    { 0, trace_data-&amp;gt;offsets.srcaddr, aggr_static_uint32_t },
-    { 0, trace_data-&amp;gt;offsets.dPkts, aggr_sum_uint32_t },
-    { 0, trace_data-&amp;gt;offsets.dOctets, aggr_sum_uint32_t },
-    { 0, trace_data-&amp;gt;offsets.tcp_flags, aggr_or_uint16_t }
+    { 0, trace_data-&amp;gt;offsets.srcaddr, RULE_STATIC | RULE_S1_32, NULL },
+    { 0, trace_data-&amp;gt;offsets.dPkts, RULE_SUM | RULE_S1_32, NULL },
+    { 0, trace_data-&amp;gt;offsets.dOctets, RULE_SUM | RULE_S1_32, NULL },
+    { 0, trace_data-&amp;gt;offsets.tcp_flags, RULE_OR | RULE_S1_16, NULL }
   };&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The mapping of the RULE to the function is done using a &lt;code&gt;switch&lt;/code&gt; case: (3)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* for loop for the group-aggregation */
for (int j = 0; j &amp;lt; binfos[i].num_aggr; j++) {
  switch (binfos[i].aggr[j].op) {
    ...
    case RULE_SUM | RULE_S1_32:
      binfos[i].aggr[j].func = aggr_sum_uint32_t;
      break;
      ...
  }    
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The aggregation functions are auto-generated using a python script &lt;code&gt;fun-gen.py&lt;/code&gt;. (4) In addition, the group aggregation records now also have common fields from the filter stage, so a query like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;filter f {
  srcport = 80
}    
...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;would give group aggregation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;No. of Groups: 32 (Aggregations)

... Sif   SrcIPaddress    SrcP  DIf   DstIPaddress    ...
... 0     216.92.252.68   80    0     192.168.0.135   ...
... 0     74.125.43.155   80    0     192.168.0.135   ... 
... 0     209.85.129.104  80    0     192.168.0.135   ... &lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/pipeline_8h.html'&gt;&lt;code&gt;pipeline&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/auto__assign_8c.html'&gt;&lt;code&gt;auto_assign&lt;/code&gt; references &amp;#8594;&lt;/a&gt;&lt;br /&gt;(4) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/namespacefun__gen.html'&gt;&lt;code&gt;fun_gen&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Execution Engine Verbosity Levels</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/19/execution-engine-verbosity-levels"/>
   <updated>2012-03-19T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/19/execution-engine-verbosity-levels</id>
   <content type="html">&lt;p&gt;Without verbosity or debugging levels the echo is minimalistic with only the end-result.&lt;br /&gt;Offcourse, since the ungrouper is yet to be implemented, the run results in no echo.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ bin/flowy-engine bin/traces-long.ft bin/query.json&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Verbosity Levels:&lt;/p&gt;

&lt;p&gt;The engine is interactive to help you choose the right switches with required options.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ bin/flowy-engine bin/traces-long.ft bin/query.json --verbose
flowy-engine: option `--verbose&amp;#39; requires an argument

[engine]$ bin/flowy-engine bin/traces-long.ft bin/query.json --verbose
ERROR: valid verbosity levels: (1-3)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--verbose=1&lt;/code&gt;: shows the results of each stage of the pipeline&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ bin/flowy-engine bin/traces-long.ft bin/query.json --verbose=1
No. of Filtered Records: 166
...
No. of Groups: 32 (Aggregations)
...
No. of Filtered Groups: 5 (Aggregations)
...
No. of Merged Groups: 3 (Tuples)
...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--verbose=2&lt;/code&gt;: additionally also shows the intermediate results of each stage of the pipeline&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ bin/flowy-engine bin/traces-long.ft bin/query.json --verbose=1
No. of Filtered Records: 166
...
No. of Sorted Records: 166
...
No. of Unique Records: 32
...
No. of Groups: 32 (Verbose Output)
...

... 0     216.137.61.203  80    0     192.168.0.135 ... 
... 0     216.137.61.203  80    0     192.168.0.135 ... 

... 0     8.12.214.126    80    0     192.168.0.135 ...
... 0     8.12.214.126    80    0     192.168.0.135 ...

No. of Groups: 32 (Aggregations)
...

... 0     216.137.61.203  80    0     192.168.0.135 ... 
... 0     8.12.214.126    80    0     192.168.0.135 ...

No. of Filtered Groups: 5 (Aggregations)
...
No. of (to be) Matched Groups: 15 
...

... 0     192.168.0.135   0     0     204.160.123.126 80    ...
... 0     87.238.86.121   80    0     192.168.0.135   0     ...

... 0     192.168.0.135   0     0     216.46.94.66    80    ... 
... 0     216.46.94.66    80    0     192.168.0.135   0     ... 	

No. of Merged Groups: 3 (Tuples)
...

... 0     192.168.0.135   0     0     216.46.94.66    80    ... 
... 0     216.46.94.66    80    0     192.168.0.135   0     ... 	&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--verbose=3&lt;/code&gt;: additionally also prints the original flow-record trace.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#
# mode:                 normal
# capture hostname:     ihp.jacobs.jacobs-university.de
# capture start:        Fri, 02 Mar 2012 00:00:01 +0100
# capture end:          Fri, 02 Mar 2012 00:05:00 +0100
# capture period:       299 seconds
# compress:             on
# byte order:           little
# stream version:       3
# export version:       5
# lost flows:           0
# corrupt packets:      0
# sequencer resets:     0
# capture flows:        430
#

... Sif SrcIPaddress    SrcP  DIf   DstIPaddress    DstP  ... 
...  0  10.50.244.59    138   0     10.50.255.255   138   ... 


No. of Filtered Records: 166
...
No. of Sorted Records: 166
...
No. of Unique Records: 32
...
No. of Groups: 32 (Verbose Output)
...
No. of Groups: 32 (Aggregations)
...
No. of Filtered Groups: 5 (Aggregations)
...
No. of (to be) Matched Groups: 15 
...
No. of Merged Groups: 3 (Tuples)
...&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Resolved Grouper Segfaults</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/12/resolved-grouper-segfaults"/>
   <updated>2012-03-12T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/12/resolved-grouper-segfaults</id>
   <content type="html">&lt;p&gt;Removed GNU99 extensions to increase portability&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Replaced &lt;code&gt;Boolean enum&lt;/code&gt; with &lt;code&gt;C99 bool&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;Removed Anonymous Unions&lt;/li&gt;

&lt;li&gt;Added a &lt;code&gt;C99&lt;/code&gt; flag in the Makefile.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The order of arguments passed in &lt;code&gt;qsort_r(…)&lt;/code&gt; and &lt;code&gt;bsearch_r(…)&lt;/code&gt; was incorrect. This could also be due to the different order of arguments in &lt;code&gt;glibc&lt;/code&gt; and &lt;code&gt;BSD&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void 
qsort_r(
        void *base, size_t nel, 
        size_t width, 
        void *thunk, 
        int (*compar)(void *, const void *, const void *)
       );
		
void *
bsearch_r(
          const void *key, 
          const void *base, 
          size_t nel, 
          size_t width, 
          void *thunk, 
          int (*compar) (const void *, const void *)
         );&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Removed the &lt;code&gt;--absolute&lt;/code&gt; switch. This should be implied from the supplied query.&lt;/p&gt;

&lt;p&gt;Pretty Printing each sub stage of the grouper pipeline.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;printing the sorted filtered records on &lt;code&gt;--debug&lt;/code&gt;. The records are sorted to the first rule in the grouper module:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grouper g_www_req {
   module g1 {
      srcip = srcip
	  ...
   }	  
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then the filtered records are sorted according to the &lt;code&gt;srcip&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ ./flowy-engine --debug traces-long.ft query.json

No. of Sorted Records: 166

...	SrcIPaddress    ...

...	4.23.48.126     ...
...	4.23.48.126     ...
...	4.23.48.126     ...
...	8.12.214.126    ...&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;printing the unique sorted records on &lt;code&gt;--debug&lt;/code&gt;. The duplicate sorted records are filtered out:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;No. of Unique Records: 32

...	SrcIPaddress    ...

...	4.23.48.126     ...
...	8.12.214.126    ... &lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;printing the formed groups on &lt;code&gt;--debug&lt;/code&gt;. The example shows groups formed with records having the same &lt;code&gt;srcIP&lt;/code&gt; and &lt;code&gt;dstIP&lt;/code&gt; and having &lt;code&gt;srcP 80&lt;/code&gt; (which was the rule in the filter stage)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;No. of Groups: 32 (Verbose Output)

...	SrcIPaddress    SrcP  DIf   DstIPaddress   ...

...	4.23.48.126     80    0     192.168.0.135  ...
...	4.23.48.126     80    0     192.168.0.135  ...

...	8.12.214.126    80    0     192.168.0.135  ...
...	8.12.214.126    80    0     192.168.0.135  ...&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>New Grouper Features</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/12/new-grouper-features"/>
   <updated>2012-03-12T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/12/new-grouper-features</id>
   <content type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pretty printing group aggregations as new flow record representatives. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grouper g_www_res {
   module g1 {
      srcip = srcip
      dstip = dstip
   }
   aggregate srcip, dstip, sum(bytes) as bytes, bitOR(tcp_flags) as flags, 
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will form groups with same &lt;code&gt;srcIP&lt;/code&gt; and &lt;code&gt;dstIP&lt;/code&gt; and display as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;No. of Groups: 32 (Aggregations)

...	   SrcIPaddress    ...	  	DstIPaddress      OR(Fl)    Sum(Octets)

...	   4.23.48.126     ...  	192.168.0.135     3         81034
...	   8.12.214.126    ...  	192.168.0.135     2         5065
...	   80.157.170.88   ...  	192.168.0.135     6         18025&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The idea is to return aggregates, common fields and sets of uncommon fields.&lt;br /&gt;The feature to return set of uncommon fields still needs to be implemented.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;There can be a situtation as in the example above, where the query designer might incorrectly ask for aggregation on a field already specified in a grouper module. Of course, the aggregation does not make any sense, since the grouped record will always have the same value for that field. The engine is now smart to realize it and ignores such aggregations as above.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Records are clubbed together into one group if no group modules are defined&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grouper g_www_res {
   module g1 {}
   aggregate sum(bytes) as bytes
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Previously such a query would form groups for each individual filtered record. That was less useful since then one could not just perform meaningful aggregates (as above). Now, when the group modules are empty, all the filtered records are clubbed into one group to allow such aggregations.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;No. of Groups: 1 (Aggregations)

...    Sum(Octets)
...    2356654&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
 </entry>
 
 <entry>
   <title>flow tools on AMD64</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/12/flow-tools-on-amd64"/>
   <updated>2012-03-12T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/12/flow-tools-on-amd64</id>
   <content type="html">&lt;p&gt;The &lt;code&gt;START&lt;/code&gt; and &lt;code&gt;END&lt;/code&gt; timestamps on pretty-print are emitting garbage values.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ flow-cat traces.ft | flow-print -f 5

Start             End                ...
0309.03:21:34.835 0309.03:21:34.835  ...
0107.18:47:30.422 0107.18:47:30.422  ...
0825.21:13:44.389 0720.19:49:18.819  ...
0627.22:48:48.456 0627.22:48:48.456  ...
0502.00:22:40.523 0502.00:22:40.523  ...
0305.12:08:28.306 0131.20:53:46.834  ...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It turns out the original &lt;code&gt;flow-tools v0.68&lt;/code&gt; (1) does not work well with &lt;code&gt;AMD64&lt;/code&gt; (2). There is an active forked project of original &lt;code&gt;flow-tools&lt;/code&gt; (3) that works on 64-bit systems.&lt;/p&gt;

&lt;p&gt;Installing &lt;a href='https://github.com/downloads/vbajpai/mthesis-src/flow-tools-0.68.4.tar.bz2'&gt;flow-tools 0.68.4 &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install
$ flow-cat traces.ft | flow-print -f 5

Start             End                ...
1207.23:58:54.835 1207.23:58:54.835  ...
1207.23:58:58.422 1207.23:58:58.422  ...
1207.23:58:00.389 1207.23:58:54.819  ...
1207.23:59:12.456 1207.23:59:12.456  ...
1207.23:59:12.523 1207.23:59:12.523  ...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and now the engine also spits out timestamps in correct order:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ ./flowy-engine --debug traces-long.ft query.json

Start             End                ...
1207.23:58:54.835 1207.23:58:54.835  ...
1207.23:58:58.422 1207.23:58:58.422  ...
1207.23:58:00.389 1207.23:58:54.819  ...
1207.23:59:12.456 1207.23:59:12.456  ...
1207.23:59:12.523 1207.23:59:12.523  ...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://www.splintered.net/sw/flow-tools'&gt;original flow-tools &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://ensight.eos.nasa.gov/FlowViewer/faq.html#14'&gt;flow-tools on AMD64 FAQ by FlowViewer &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://code.google.com/p/flow-tools/'&gt;forked flow-tools &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Preliminary JSON Parsing Experimentation</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/03/01/preliminary-json-parsing-experimentation"/>
   <updated>2012-03-01T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/03/01/preliminary-json-parsing-experimentation</id>
   <content type="html">&lt;p&gt;Preliminary JSON parsing experimentation&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;added filter comparison functions in &lt;code&gt;auto_assign.c&lt;/code&gt; using &lt;code&gt;fun_gen.py&lt;/code&gt; (1, 2)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;using the new comparison functions in the &lt;code&gt;filter_rule&lt;/code&gt; struct (3)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;added a temporary &lt;code&gt;filter-poop.py&lt;/code&gt; to spit out JSON representation of a python object using the &lt;code&gt;json&lt;/code&gt; module (4, 5)&lt;/p&gt;

&lt;p&gt;where the python class is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class FilterStatement: 		  
  def __init__(self, name, value, datatype, delta, op):
    self.offset = {
      &amp;#39;name&amp;#39;: name,
      &amp;#39;value&amp;#39;: value,
      &amp;#39;datatype&amp;#39;: datatype
    }		    
    self.delta = delta
    self.op = op		&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;executing the python file gives:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python filter-poop.py
{
  &amp;quot;delta&amp;quot;: 0, 
  &amp;quot;op&amp;quot;: &amp;quot;RULE_EQ&amp;quot;, 
  &amp;quot;offset&amp;quot;: {
    &amp;quot;datatype&amp;quot;: &amp;quot;u_int16&amp;quot;, 
    &amp;quot;name&amp;quot;: &amp;quot;dstport&amp;quot;, 
    &amp;quot;value&amp;quot;: 80
  }
} 		    &lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The execution engine can now parse this JSON file to read the parameters for the filter stage (for now) (3, 6)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./flowy-engine --absolute traces.ft query.json

No. of Filtered Records: 4

...	SrcIPaddress    SrcP  DIf   DstIPaddress    DstP  ...
...	10.50.239.4     39788 0     209.85.135.19   80    ...
...	10.50.239.4     40339 0     81.19.80.14     80    ...
...	10.50.239.4     46499 0     209.85.135.19   80    ...&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources -&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/auto__assign_8c.html'&gt;&lt;code&gt;auto_assign&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/fun__gen_8py.html'&gt;&lt;code&gt;fun_gen&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(4) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/namespacefilter-poop.html'&gt;&lt;code&gt;filter-poop&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;External Resources -&lt;/p&gt;

&lt;p&gt;(5) &lt;a href='http://docs.python.org/library/json.html'&gt;&lt;code&gt;python json module&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(6) &lt;a href='http://oss.metaparadigm.com/json-c/'&gt;&lt;code&gt;json-c library&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Debugging the Execution Engine</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/27/debugging-the-execution-engine"/>
   <updated>2012-02-27T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/27/debugging-the-execution-engine</id>
   <content type="html">&lt;p&gt;Debugging the execution engine.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Added a &lt;s&gt;`DEBUGENGINE` macro&lt;/s&gt; &lt;code&gt;debug bool&lt;/code&gt; in &lt;code&gt;base_header.h&lt;/code&gt; (1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Changes in &lt;code&gt;ftreader&lt;/code&gt; (2)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Added &lt;code&gt;ftio_check_xfield(…)&lt;/code&gt; to check the proper format before retrieving the xfield using &lt;code&gt;ftio_xfield(…)&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;Added &lt;code&gt;flow_print_record(…)&lt;/code&gt; to print the flow-records.&lt;/li&gt;

&lt;li&gt;&lt;code&gt;ftreader&lt;/code&gt; now prints the read trace in a &lt;code&gt;flow-print-f5&lt;/code&gt; format when &lt;code&gt;DEBUGENGINE&lt;/code&gt; is set.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Changes in &lt;code&gt;pipeline&lt;/code&gt; (3)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Saving pointers to the filtered records when &lt;code&gt;DEBUGENGINE&lt;/code&gt; is set.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct branch_info {
  
  /* have to be filled manually */
  ...
  
#ifdef DEBUGENGINE
  char** filtered_records;
  size_t num_filtered_records;  
#endif
  
  /* will be filled by individual branches */
  ...
};&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Changes in &lt;code&gt;flowy&lt;/code&gt; (4)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Added a bunch load of code comments to describe the flow.&lt;/li&gt;

&lt;li&gt;Added separate macros for each stage of the pipeline for now, until the segfault is resolved.&lt;/li&gt;

&lt;li&gt;Printing the filtered flow-records when the &lt;s&gt;`DEBUGENGINE`&lt;/s&gt; &lt;code&gt;--debug&lt;/code&gt; is set.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources -&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/base__header_8h.html'&gt;&lt;code&gt;base_header&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/ftreader_8c.html'&gt;&lt;code&gt;ftreader&lt;/code&gt; reference &amp;#8594;&lt;/a&gt; &lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/pipeline_8h.html'&gt;&lt;code&gt;pipeline&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(4) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Command Line Parsing of the Execution Engine</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/27/command-line-parsing-of-the-execution-engine"/>
   <updated>2012-02-27T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/27/command-line-parsing-of-the-execution-engine</id>
   <content type="html">&lt;p&gt;Command Line Parsing of the Execution Engine&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Renamed &lt;code&gt;base_header.h&lt;/code&gt; to &lt;code&gt;base.{h,c}&lt;/code&gt; (1)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Defined global variables (command line flags) used in &lt;code&gt;base.{h,c}&lt;/code&gt; (1)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Moved &lt;code&gt;usageError(…)&lt;/code&gt; to &lt;code&gt;error_functions&lt;/code&gt; (2)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;using &lt;code&gt;debug&lt;/code&gt; and &lt;code&gt;absolute&lt;/code&gt; global flags now instead of macros (3)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;using &lt;code&gt;getopt_long(…)&lt;/code&gt; for command line parsing (3)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;print usage on insufficient arguments&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ ./flowy-engine
Usage: ./flowy-engine $TRACE&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;track invalid options&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ ./flowy-engine -x traces.ft
flowy-engine: invalid option -- x&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;code&gt;--debug&lt;/code&gt; flag: &lt;code&gt;flow-print&lt;/code&gt; functionality&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine]$ ./flowy-engine --debug traces.ft
 #
 # mode:                 normal
 # capture hostname:     melnikovkolya-laptop
 # capture start:        (null)  
 # capture end:          Mon Feb 12 18:29:48 2418
 # capture period:       299 seconds
 # compress:             on
 # byte order:           little
 # stream version:       3
 # export version:       5
 # lost flows:           0
 # corrupt packets:      0
 # sequencer resets:     0
 # capture flows:        132
 #

... SrcIPaddress    SrcP  DIf   DstIPaddress    DstP  ...

... 10.50.249.229   138   0     10.50.255.255   138   ...
... 10.50.223.240   138   0     10.50.255.255   138   ...&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;&lt;s&gt;`--absolute` flag: can be used to restrict functionality&lt;/s&gt;
&lt;pre&gt;&lt;code&gt;[engine]$ ./flowy-engine --absolute traces.ft

No. of Filtered Records: 4

...	SrcIPaddress    SrcP  DIf   DstIPaddress    DstP  ...

...	10.50.239.4     39788 0     209.85.135.19   80    ...
...	10.50.239.4     40339 0     81.19.80.14     80    ...
...	10.50.239.4     46499 0     209.85.135.19   80    ...&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources -&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/base_8h.html'&gt;&lt;code&gt;base&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/error__functions_8h.html'&gt;&lt;code&gt;error_functions&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/flowy_8c.html'&gt;&lt;code&gt;flowy&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;br /&gt;(4) &lt;a href='http://mthesis.vaibhavbajpai.com/post/19179727822/resolved-grouper-segfaults'&gt;resolved grouper segfaults &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Refactoring the Execution Engine</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/24/refactoring-the-execution-engine"/>
   <updated>2012-02-24T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/24/refactoring-the-execution-engine</id>
   <content type="html">&lt;p&gt;Refactoring the execution engine.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Added a &lt;s&gt;`base_header`&lt;/s&gt; &lt;code&gt;base&lt;/code&gt; for common lib includes (1).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt='base-header' src='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/base_8h__incl.png' /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Added &lt;code&gt;error_functions&lt;/code&gt; for common error reporting, currently being used by &lt;code&gt;flowy&lt;/code&gt; (2).&lt;/li&gt;

&lt;li&gt;Indented the whole project to use 2 spaces for a tab.&lt;/li&gt;

&lt;li&gt;Added &lt;code&gt;grouper_fptr, merger_fptr&lt;/code&gt; headers (why were they missing again :-/) for the corresponding sources (3, 4).&lt;/li&gt;

&lt;li&gt;Added more details in the Doxygen documentation, added documentation for &lt;code&gt;ftlib&lt;/code&gt; (5).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt='flow-query' src='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/structflowquery__coll__graph.png' /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Moved all external lib includes in the header for consistency, added include-guards in few missed headers.&lt;/li&gt;

&lt;li&gt;Separated out pipeline structs in &lt;code&gt;pipeline&lt;/code&gt; header to resolve circular dependencies to avoid forward declarations (6)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt='pipeline' src='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/pipeline_8h__dep__incl.png' /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Updated &lt;code&gt;fun_gen&lt;/code&gt; to reflect aforementioned resolution of circular dependencies (7)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resources -&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/base__header_8h.html'&gt;&lt;code&gt;base_header&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(2) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/error__functions_8h.html'&gt;&lt;code&gt;error_functions&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(3) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/merger__fptr_8h.html'&gt;&lt;code&gt;merger_fptr&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(4) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/grouper__fptr_8h.html'&gt;&lt;code&gt;grouper_fptr&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(5) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/ftlib_8h.html'&gt;&lt;code&gt;ftlib&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(6) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/pipeline_8h.html'&gt;&lt;code&gt;pipeline&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(7) &lt;a href='http://dl.dropbox.com/u/500389/mthesis/docs-engine/html/namespacefun__gen.html'&gt;&lt;code&gt;fun_gen&lt;/code&gt; reference &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>The Execution Engine currently segfaults</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/23/the-execution-engine-currently-segfaults"/>
   <updated>2012-02-23T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/23/the-execution-engine-currently-segfaults</id>
   <content type="html">&lt;p&gt;&lt;img alt='Imgur' src='http://i.imgur.com/qiyVa.png' /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cflow --format=posix --omit-arguments flowy.c
    1 main: int (), &amp;lt;flowy.c 200&amp;gt;
    6     ft_open: &amp;lt;&amp;gt;
   14     branch_start: void * (), &amp;lt;flowy.c 146&amp;gt;
   15         filter: char ** (), &amp;lt;flowy.c 57&amp;gt;
   22         grouper: &amp;lt;&amp;gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So essentially the &lt;code&gt;build_record_trees(…)&lt;/code&gt; function segfaults when it calls &lt;code&gt;qsort_r(…)&lt;/code&gt;. Need to investigate on it &amp;#8230;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Removing Extraneous Files from the Execution Engine</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/23/removing-extraneous-files-from-the-execution-engine"/>
   <updated>2012-02-23T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/23/removing-extraneous-files-from-the-execution-engine</id>
   <content type="html">&lt;p&gt;The engine currently uses comparison functions as the default method for efficient rule processing. These functions are auto-generated by &lt;code&gt;fun_gen.py&lt;/code&gt; to &lt;code&gt;auto_comps.{h,c}&lt;/code&gt; and later called by &lt;code&gt;grouper_fptr.c&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The same python script also generates &lt;code&gt;auto_switch.c&lt;/code&gt; as an alternative method which can be later called by &lt;code&gt;grouper_switch.c&lt;/code&gt;. Since, this method is not currently used by the program. I have removed it from the &lt;code&gt;HEAD&lt;/code&gt; since it can anyway be later retrieved from the &lt;code&gt;git&lt;/code&gt; history.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ rm auto_switch.c grouper_switch.c&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The engine also performs a divide and conquer approach for fast relative comparsions. The code was initially prepared as a separate compilation unit for testing purposes and was later incorporated into the engine. The separate units are therefore no longer needed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ rm treesearch.c treesearchmain.c&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;filter&lt;/code&gt; stage of the processing pipeline was moved out into a separate compilation unit to allow benchmarking with contemporary tools like &lt;code&gt;flow-tools&lt;/code&gt; and &lt;code&gt;nf-dump&lt;/code&gt;. This should be done by passing an &lt;code&gt;--absolute&lt;/code&gt; switch to the engine, which reduces its functionality down to only the &lt;code&gt;filter&lt;/code&gt; stage. As such, I am removing the separate units.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ rm filter.c&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The references to these units were also removed from the &lt;code&gt;Makefile&lt;/code&gt;.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Installing and Running the Execution Engine</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/23/installing-and-running-the-execution-engine"/>
   <updated>2012-02-23T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/23/installing-and-running-the-execution-engine</id>
   <content type="html">&lt;p&gt;Install &lt;code&gt;flow-tools&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;For 32-bit machines, go ahead, but for &lt;code&gt;AMD64&lt;/code&gt; follow (1)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install https://raw.github.com/hoxworth/homebrew/25921d95ff10d1b505e933a581e0b4fb8d72d952/Library/Formula/flow-tools.rb&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Building on the command line&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ make&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Building using Xcode&lt;/p&gt;

&lt;p&gt;&lt;img alt='Imgur' src='http://i.imgur.com/NrB3s.png' /&gt;&lt;/p&gt;

&lt;p&gt;Running on the command line&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ ./flowy-engine --help
[engine] $ ./flowy-engine $TRACE&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Running using Xcode&lt;/p&gt;

&lt;p&gt;Goto Product &amp;#8594; Edit Scheme to Arguments.&lt;/p&gt;

&lt;p&gt;&lt;img alt='Imgur' src='http://i.imgur.com/vRdSN.png' /&gt;&lt;/p&gt;

&lt;p&gt;Resources:&lt;/p&gt;

&lt;p&gt;(1) &lt;a href='http://mthesis.vaibhavbajpai.com/post/19183305904/flow-tools-on-amd64'&gt;&lt;code&gt;flow-tools&lt;/code&gt; on &lt;code&gt;AMD64&lt;/code&gt; &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Reverse Engineering the C Execution Engine</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/22/reverse-engineering-the-c-execution-engine"/>
   <updated>2012-02-22T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/22/reverse-engineering-the-c-execution-engine</id>
   <content type="html">&lt;p&gt;Install Doxygen&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install doxygen&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Initialize Doxygen&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ doxygen -g&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the Doxyfile&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[...]

# Extract documentation even from those elements you haven&amp;#39;t yet commented.
EXTRACT_ALL = YES	

# Extract the relevant parts of the source and associate them with your description.
INLINE_SOURCE = YES

# Use GraphVIZ for class and collaboration diagrams.
HAVE_DOT = YES

# Generate a dependency graph for functions and methods.
CALL_GRAPH = YES

# Skip generating LaTeX sources for PDF.
GENERATE_LATEX = NO

# Show directory hierarchy in the documentation
SHOW_DIRECTORIES = YES

# Recursively search for input files.
RECURSIVE = YES&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Execute Doxygen&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[engine] $ doxygen Doxyfile&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;flowy.c&lt;/code&gt; Dependency Graph&lt;/p&gt;

&lt;p&gt;&lt;img alt='Imgur' src='http://i.imgur.com/QXVy4.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;flowy.c&lt;/code&gt; &amp;#8594; &lt;code&gt;main(…)&lt;/code&gt; Call Graph&lt;/p&gt;

&lt;p&gt;&lt;img alt='Imgur' src='http://i.imgur.com/uEOVw.png' /&gt;&lt;/p&gt;

&lt;p&gt;A similar Call Graph can also be generated using &lt;code&gt;cflow&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install cflow

$ cflow --format=posix --omit-arguments flowy.c
    1 main: int (), &amp;lt;flowy.c 204&amp;gt;
    2     ft_open: &amp;lt;&amp;gt;
    3     calloc: &amp;lt;&amp;gt;
    4     perror: &amp;lt;&amp;gt;
    5     exit: &amp;lt;&amp;gt;
    6     assign_fptr: &amp;lt;&amp;gt;
    7     malloc: &amp;lt;&amp;gt;
    8     pthread_attr_init: &amp;lt;&amp;gt;
    9     pthread_create: &amp;lt;&amp;gt;
   10     branch_start: void * (), &amp;lt;flowy.c 149&amp;gt;
   11         filter: char ** (), &amp;lt;flowy.c 58&amp;gt;
   12             malloc: &amp;lt;&amp;gt;
   13             perror: &amp;lt;&amp;gt;
   14             exit: &amp;lt;&amp;gt;
   15             func: &amp;lt;&amp;gt;
   16             realloc: &amp;lt;&amp;gt;
   17         printf: &amp;lt;&amp;gt;
   18         grouper: &amp;lt;&amp;gt;
   19         free: &amp;lt;&amp;gt;
   20         group_filter: struct group (), &amp;lt;flowy.c 92&amp;gt;
   21         perror: &amp;lt;&amp;gt;
   22         exit: &amp;lt;&amp;gt;
   23         pthread_exit: &amp;lt;&amp;gt;
   24     pthread_attr_destroy: &amp;lt;&amp;gt;
   25     pthread_join: &amp;lt;&amp;gt;
   26     printf: &amp;lt;&amp;gt;
   27     free: &amp;lt;&amp;gt;
   28     merger: &amp;lt;&amp;gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;struct flowquery&lt;/code&gt; Collaboration Graph&lt;/p&gt;

&lt;p&gt;&lt;img alt='Imgur' src='http://i.imgur.com/tj99w.png' /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.vaibhavbajpai.com/documents/thesis/docs/docs-engine/html/index.html'&gt;Complete Documentation &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Reverse Engineering the Python Parser</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/21/reverse-engineering-the-python-parser"/>
   <updated>2012-02-21T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/21/reverse-engineering-the-python-parser</id>
   <content type="html">&lt;p&gt;Install GraphVIZ&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install graphviz
$ brew linkapps&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install PyLint&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install pylint&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generate UML Diagrams using PyReverse&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyreverse -o png -p parser parser/&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;UML Diagram of the Python Parser&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.vaibhavbajpai.com/documents/thesis/docs/docs-parser/packages-parser.png'&gt;Packages &amp;#8594;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.vaibhavbajpai.com/documents/thesis/docs/docs-parser/classes-parser.png'&gt;Classes &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Installing and Running the Parser</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/21/installing-and-running-the-parser"/>
   <updated>2012-02-21T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/21/installing-and-running-the-parser</id>
   <content type="html">&lt;p&gt;Install PyTables&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install hdf5
$ brew install lzo

$ pip install numpy
$ pip install numexpr
$ pip install cython&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Python Lex &amp;amp; Yacc&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install ply==2.5&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install &lt;code&gt;pyflowtools&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ brew install https://raw.github.com/hoxworth/homebrew/25921d95ff10d1b505e933a581e0b4fb8d72d952/Library/Formula/flow-tools.rb
$ pip install git+https://git.gitorious.org/flow-tools/pyflowtools.git&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install Misc Dependencies&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip install netaddr&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Freeze&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pip freeze  
Cython==0.15.1
distribute==0.6.24
logilab-astng==0.23.1
logilab-common==0.57.1
netaddr==0.7.6
numexpr==2.0.1
numpy==1.6.1
ply==2.5
pyflowtools==0.3.4.1
pylint==0.25.1
tables==2.3.1
wsgiref==0.1.2&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Test Run Flowy&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[parser] $ python ft2hdf.py ../../traces/ ft-traces.h5
[parser] $ python printhdf.py ft-traces.h5
[parser] $ python print_hdf_in_step.py ft-traces.h5
[parser] $ python flowy.py query.flw&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;query.flw&lt;/code&gt; refers to the input &lt;code&gt;ft-traces.h5&lt;/code&gt; and the to-be created &lt;code&gt;output.h5&lt;/code&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>v2.0: it's a start</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/20/v20-its-a-start"/>
   <updated>2012-02-20T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/20/v20-its-a-start</id>
   <content type="html">&lt;p&gt;The evolution of the core of the former Python implementation in C.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt; git show v0.0

tag v0.0
Tagger: Vaibhav Bajpai &amp;lt;contact@vaibhavbajpai.com&amp;gt;
Date:   Thu May 17 10:48:02 2012 +0200
Commit 8cb309c8a956c99e6b1494eddb601c8f6a520696

* read flow-records into memory
* rewrite of the execution pipeline in C (non functional)
* efficient rule processing with dedicated function pointers
* reduced grouper complexity using qsort(...) and bsearch(...)
* concerns
        - flow query is currently hardcoded in pipeline structs
        - functions assume specific uintX_t offsets
        - numerous grouper segfaults
        - no group filter
        - commented out merger (segfaults when uncommented)
        - no ungrouper
        - code dependent on GNU99 extensions
        - some headers are missing include guards
        - unused extraneous source files and headers&lt;/code&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>Github Repositories</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/20/github-repositories"/>
   <updated>2012-02-20T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/20/github-repositories</id>
   <content type="html">&lt;p&gt;&lt;a href='https://github.com/vbajpai/nfql'&gt;NFQL Repository &amp;#8594;&lt;/a&gt;&lt;br /&gt;&lt;a href='https://github.com/vbajpai/mastersthesis'&gt;Thesis Repository &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Masters Thesis Proposal</title>
   <link href="http://vbajpai.github.com/blog.nfql/2012/02/01/masters-thesis-proposal"/>
   <updated>2012-02-01T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2012/02/01/masters-thesis-proposal</id>
   <content type="html">&lt;p&gt;I submitted my thesis proposal today.&lt;/p&gt;

&lt;p&gt;&lt;a href='https://github.com/downloads/vbajpai/blog.nfql/vbajpai-proposal.pdf'&gt;Masters Thesis Proposal &amp;#8594;&lt;/a&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>State of the Art</title>
   <link href="http://vbajpai.github.com/blog.nfql/2011/12/25/state-of-the-art"/>
   <updated>2011-12-25T00:00:00+01:00</updated>
   <id>http://vbajpai.github.com/blog.nfql/2011/12/25/state-of-the-art</id>
   <content type="html">&lt;p&gt;&lt;a href='http://dl.dropbox.com/u/500389/mthesis/f.pdf'&gt;F &amp;#8594;&lt;/a&gt;&lt;br /&gt;Johannes Schauer, Nikolay Melnikov, Jürgen Schönwälder&lt;br /&gt;December 2011.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://dl.dropbox.com/u/500389/mthesis/ipv6transeval.pdf'&gt;Automated Failure Identification under IPv6 Transition Mechanisms &amp;#8594;&lt;/a&gt;&lt;br /&gt;Vaibhav Bajpai, Nikolay Melnikov, Jürgen Schönwälder&lt;br /&gt;December 2011&lt;/p&gt;

&lt;p&gt;&lt;a href='http://dl.dropbox.com/u/500389/mthesis/jschauer-thesis.pdf'&gt;Flowy 2.0: Fast Execution of Stream-based IP Flow Queries &amp;#8594;&lt;/a&gt;&lt;br /&gt;Johannes Schauer, Bachelors Thesis, May 2011.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5990668'&gt;Flow signatures of popular applications &amp;#8594;&lt;/a&gt;&lt;br /&gt;&lt;a href='http://cnds.eecs.jacobs-university.de/slides/2011-im-flow-signatures.pdf'&gt;Slides &amp;#8594;&lt;/a&gt;&lt;br /&gt;Vladislav Perelman, Nikolay Melnikov, Jürgen Schönwälder&lt;br /&gt;IM 2011, Dublin, May 2011.&lt;/p&gt;

&lt;p&gt;&lt;a href='https://svn.eecs.jacobs-university.de/svn/eecs/archive/msc-2010/nmelnikov.pdf'&gt;Cybermetrics: Identication of Users Through Network Flow Analysis &amp;#8594;&lt;/a&gt;&lt;br /&gt;Nikolay Melnikov, Masters Thesis, August 2010.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://cnds.eecs.jacobs-university.de/slides/2010-ietf-78-nmrg-app-signatures.pdf'&gt;Flow Signatures of Popular Applications &amp;#8594;&lt;/a&gt;&lt;br /&gt;Nikolay Melnikov&lt;br /&gt;78th IETF, Maastricht, July 2010.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.springerlink.com/content/l85hk73487086024/fulltext.pdf'&gt;Cybermetrics: User Identiﬁcation through Network Flow Analysis &amp;#8594;&lt;/a&gt;&lt;br /&gt;&lt;a href='http://cnds.eecs.jacobs-university.de/slides/2010-aims-cybermetrics.pdf'&gt;Slides &amp;#8594;&lt;/a&gt;&lt;br /&gt;Nikolay Melnikov, Jürgen Schönwälder AIMS 2010, Zurich, June 2010.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.springerlink.com/content/a565783288655j67/fulltext.pdf'&gt;Implementation of a Stream-Based IP Flow Record Query Language &amp;#8594;&lt;/a&gt;&lt;br /&gt;&lt;a href='http://cnds.eecs.jacobs-university.de/slides/2010-aims-flowy-implementation.pdf'&gt;Slides &amp;#8594;&lt;/a&gt; &lt;br /&gt;Kaloyan Kanev, Nikolay Melnikov, Jürgen Schönwälder&lt;br /&gt;AIMS 2010, Zurich, June 2010.&lt;/p&gt;

&lt;p&gt;&lt;a href='https://svn.eecs.jacobs-university.de/svn/eecs/archive/bsc-2010/vperelman.pdf'&gt;Flow Signatures of Popular Applications &amp;#8594;&lt;/a&gt;&lt;br /&gt;Vladislav Perelman, Bachelors Thesis, May 2010.&lt;/p&gt;

&lt;p&gt;&lt;a href='https://svn.eecs.jacobs-university.de/svn/eecs/archive/bsc-2010/pnemeth.pdf'&gt;Flowy improvement using MapReduce &amp;#8594;&lt;/a&gt;&lt;br /&gt;Peter Nemeth, Bachelors Thesis, May 2010.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.springerlink.com/content/j4555jj848l8q862/fulltext.pdf'&gt;Design of a Stream-Based IP Flow Record Query Language &amp;#8594;&lt;/a&gt; &lt;br /&gt;&lt;a href='http://cnds.eecs.jacobs-university.de/slides/2009-dsom-flow-query.pdf'&gt;Slides &amp;#8594;&lt;/a&gt;&lt;br /&gt;Vladislav Marinov, Jürgen Schönwälder&lt;br /&gt;DSOM 2009, Venice, October 2009.&lt;/p&gt;

&lt;p&gt;&lt;a href='https://svn.eecs.jacobs-university.de/svn/eecs/archive/msc-2009/kkanev.pdf'&gt;Flowy - Network Flow Analysis Application &amp;#8594;&lt;/a&gt;&lt;br /&gt;Kaloyan Kanev, Masters Thesis, August 2009.&lt;/p&gt;

&lt;p&gt;&lt;a href='https://svn.eecs.jacobs-university.de/svn/eecs/archive/msc-2009/vmarinov.pdf'&gt;Design of an IP Flow Record Query Language &amp;#8594;&lt;/a&gt;&lt;br /&gt;Vladislav Marinov, Masters Thesis, August 2009.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.springerlink.com/content/0m76rk7653872426/fulltext.pdf'&gt;Design of an IP Flow Record Query Language &amp;#8594;&lt;/a&gt;&lt;br /&gt;Vladislav Marinov, Jürgen Schönwälder&lt;br /&gt;AIMS 2008, Bremen, July 2008.&lt;/p&gt;</content>
 </entry>
 
 
</feed>